import React from 'react';

export interface Implementation {
  id: string;
  title: string;
  content: string;
}

export interface Method {
  id: string;
  title: string;
  content: string
  implementations?: Implementation[];
}

export interface Section {
  id: string;
  title: string;
  content: string;
  icon: string;
  methods?: Method[];
}

export interface GuideData {
  title: string;
  sections: Section[];
}

export const promptGuideData: GuideData = {
  title: "Prompting Guide",
  sections: [
    {
      id: "oversigt",
      title: "Oversigt over guiden",
      content: `Den her guide vil hj√¶lpe dig med at f√• en bedre tilgang til, hvordan du kan bruge sprogmodeller s√•som ChatGPT eller Claude p√• en mere effektiv m√•de ved at bruge ‚Äúprompt engineering.  En ‚Äúprompt‚Äù er en instruktion eller en anmodning, der gives til en sprogmodel, for at f√• et √∏nsket svar eller en bestemt form for output. Alle prompts er ikke lige gode og relevansen eller kvaliteten af sprogmodellens svar kan variere meget baseret p√• prompten. Det kr√¶ver √∏velse at l√¶re at skrive den perfekte prompt \- derfor denne guide\!

*Guiden er delt ind i tre sektioner: for begynder, √∏vede og eksperter.* 

I **begynder sektionen** diskuterer vi hvordan man kan skrive en tydelig prompt med klare instruktioner. Det er prompts, som er passende prim√¶rt, hvis du kommunikerer direkte med en sprogmodel, som for eksempel hvis du bruger ChatGPT eller Claude. 

I den **√∏vede sektion** introducerer vi user, system og assistant roller. Her deler vi ogs√• mere komplicerede metoder, samt metoder som er relevante for, hvis du selv har programmeret en sprogmodel og skal give den instruktioner for, hvordan den skal interagere med brugere. 

**Ekspert sektionen** introducerer endnu mere avancerede teknikker og g√∏r brug af eksterne v√¶rkt√∏jer for at optimere og udvide mulighederne ved prompt engineering. Flere af metoderne kr√¶ver kompetencer indenfor kodning. 

Forneden er der en oversigt over alle metoder beskrevet i vores guide og hvad, de kan bruges til. Metoderne er farvekoordineret s√• gule metoder findes i begynder sektionen, orange i den √∏vede sektionen og gr√∏nne i ekspert sektionen.

(Tryk p√• billedet for at g√∏re det st√∏rre)

Image: /Overview.png

`,
      icon: "üìö"
    },
    {
      id: "mere-om-prompt-engineering",
      title: "Mere om Prompt Engineering",
      content: "",
      icon: "üß†",
      methods: [
        {
          id: "Hvad-er-prompt-engineering",
          title: "ü§ñ Hvad er prompt engineering?",
          content: `N√•r du giver en sprogmodel en instruktion eller stiller den et sp√∏rgsm√•l, s√• ‚Äúprompter‚Äù du den. I prompt engineering fors√∏ger man at f√• mest muligt ud af modellen. Du pr√∏ver alts√• at f√• det bedste mulige svar.
`},
        {id: "typer-prompt-engineering-opgaver",
          title: "üîß Hvad kan man bruge prompt engineering til?",
          content: `Man kan bruge sprogmodeller til n√¶sten alle opgaver, som man kan t√¶nke sig til, og som man kan beskrive for sprogmodellen. De fleste opgaver falder under de f√∏lgende kategorier:

- ‚úçÔ∏è Tekstforfatning  
- üåç Overs√¶ttelse  
- üìù Opsummering af tekst  
- ü§ñ Specificering af chatbot opf√∏rsel  
- üìö Research og vidensgenerering  
- üíª Programmering  
- üìñ Undervisning  
- ‚öôÔ∏è Automatisering

Sprogmodeller er mindre gode til opgaver, som kr√¶ver sv√¶r matematik eller kompleks logik, men de g√∏r gerne et fors√∏g alligevel. Nogle af metoderne i denne guide, som [[Least-to-Most Prompting]] og [[Implementer kode i din prompt]], kan g√∏re modellerne bedre til den slags opgaver. Sprogmodeller kan ofte lave fejl eller ‚Äúhallucinere‚Äù, hvilket vil sige, at de ‚Äúfinder p√•‚Äù viden. Derfor skal man altid dobbelt tjekke vigtige informationer. 
        
          `},
        {id: "forskellen-prompt-engineering-programmering",
          title: "‚öôÔ∏è Prompt engineering vs. programmering",
          content: `Man kan l√∏se nogle af de samme opgaver med prompt engineering, som man kan med traditionel programmering. Det kan for eksempel v√¶re at automatisere opgaver eller sortere tekster. I traditionel programmering skal man nogle gange skrive meget lang og kompliceret kode. I prompt engineering ville man i stedet for give sprogmodellen en instruks i form af ren tekst. 

Nogle er bange for, at prompt engineering er for teknisk, og at de slet ikke vil kunne finde ud af det. Prompt engineering handler i dens enkleste form om at skrive gode beskeder til og med sprogmodeller. At give en god instruktion til en sprogmodel er meget ens med at give en god instruktion til en praktikant eller kollega. Der er i teorien ikke noget teknisk over det, selvom man sagtens *kan* inkludere for eksempel programmering til meget specifikke opgaver. I ekspert sektionen kr√¶ves der viden om programmering, men ellers er de fleste metoder lette at implementere med enhver baggrund. 
          
          `},
        {id: "hvem-bruger-prompt-engineering",
            title: "üë• Hvem bruger prompt engineering?",
            content: `Prompt Engineering bliver ideelt brugt af alle, der interagerer med sprogmodeller. Der kan dog v√¶re stor forskel p√•, hvordan det bliver brugt og til hvad. Her er nogle forskellige eksempler p√• prompt engineers:

‚úçÔ∏èüéì
En student, som bruger en sprogmodel til at forst√• undervisningsmateriale. Studenten uploader tekster og beder sprogmodellen om at opsummere og forklare sv√¶re koncepter. Studenten og sprogmodellen sparer omkring ideer til opgaver og hvad, studenten kan inkludere.

üìùüí°
En copywriter, som f√•r hj√¶lp af sprogmodeller til at generere tekst. Copywriteren og sprogmodellen diskuterer hvilke ord, der er mere effektive, og brainstormer titler. Sprogmodellen hj√¶lper med at rette grammatik og foresl√•r forbedringer til tekster.

üí¨ü§ñ
En programm√∏r, som har lavet en RAG chatbot til et firma og skal  give chatbotten instruktioner for, hvordan den skal h√•ndtere bruger foresp√∏rgsler og formatere dens svar. Programm√∏ren fort√¶ller for eksempel chatbotten, at den skal svare kort og formatere det i Markdown format.

            `},
            {id: "problemer-med-sprogmodeller",
              title: "‚ùì Udfordringer med sprogmodeller",
              content: `Sprogmodeller er kommet meget langt i deres udvikling, men de er stadig ikke perfekte. Derfor er det vigtigt, at man er opm√¶rksom p√• de problemer, der kan v√¶re.

‚ùóÔ∏è **Fejl og Hallucinationer**
De kan for eksempel lave fejl, for eksempel i form af ‚Äúhallucinationer‚Äù, som er n√•r de genererer forkerte informationer. De kan ogs√• lave fejl i deres analyser, s√•som i matematik opgaver. Det er et stort problem, hvis man ikke kan regne med svarene, og derfor handler mange af metoderne i guiden om at minimere fejl. Hvis muligt, skal man ogs√• tjekke sprogmodellen svar og de informationer, den giver, is√¶r hvis det er vigtige oplysninger. 

‚öñÔ∏è**Bias og Stereotyper**
Et andet problem er, at de kan have problematiske biaser og stereotyper. Sprogmodeller er tr√¶net p√• rigtig meget data, som ikke er blevet fink√¶mmet. N√•r der kan findes seksisme, racisme, homofobi, og s√• videre i tr√¶ningsdataet, kan det ogs√• ske, at sprogmodellen kan generere det. Der har for eksempel v√¶ret sager, hvor sprogmodeller har v√¶ret brugt til at hj√¶lpe med at v√¶lge kandidater til ans√¶ttelse, og hvor gode kandidater er blevet sorteret fra grundet biaser. 

üîí**Sikkerhed**
Endnu et problem er, at sprogmodeller ikke er sikre i forhold til sensitiv data. Sprogmodeller kan nemlig frit bruge ens prompts til videre at tr√¶ne sig selv. Det vil sige, at hvis man uploader en masse sensitiv data, s√• kender sprogmodellen nu den data og kan frit give det videre til andre brugere. Man skal derfor passe p√• med, hvad man fort√¶ller den. 

              `},
              {id: "gode-prompts",
                title: "üåü Er mine prompts gode?",
                content: `En prompt er generelt god, hvis du f√•r et godt svar, men det kan nogle gange v√¶re sv√¶rt at vurdere. 

Det er godt at starte med at finde ud af, om svaret er korrekt. Sprogmodeller laver sommetider fejl, og de er d√•rlige til at indr√∏mme det. Derfor skal man altid, hvis det er muligt, tjekke vigtige informationer. I nogle metoder, s√•som [[Giv reference tekster]], kan man bede modellen om at give citater, som man selv manuelt kan tjekke. Online sprogmodeller kan dog ikke give citater.  

Dern√¶st kan man pr√∏ve at eksperimentere med flere prompts og selv bestemme hvilke svar, man synes er bedst. Hvis man synes et svar er bedre end et andet, kan man ogs√• fort√¶lle sprogmodellen det, og s√• kan den m√•ske bruge den feedback til at lave et endnu bedre svar. Hvis man har programmeret et produkt til brug af andre, s√• kan man eventuelt indhente feedback fra brugerne. Endelig kan man bruge nogle af metoderne i [[Lav systematiske √¶ndringer og test det]].

                `},
                {id: "bedste-prompts",
                title: "üèÜ Bedste metode til prompt engineering?",
                content: `Mist√¶nkeligt nok insisterer de fleste studier p√•, at deres prompt engineering metode er den bedste. Hvis man s√∏ger online p√•, hvilken metode er den bedste, er der mange, der priser [[Chain of Thought]]. Det er dog sv√¶rt at svare p√•, hvilken der er bedst eller endda hvilken en, man skal bruge. Man skal for eksempel overveje:

**Hvor meget regnekraft og tid har jeg?** 
Nogle af metoderne er meget kr√¶vende, b√•de for prompteren og sprogmodellen. Hvis du ikke har meget tid eller penge til at bruge p√• tokens, kan det godt v√¶re, det ikke er de metoder, du skal v√¶lge.  

**Hvor vigtigt er det, at resultatet er det bedst, det kan v√¶re?** 
Det kan v√¶re, du har rigeligt med tid og penge, men hvis du bare skal vide, hvordan man installerer Python, s√• er det nok ikke ekspert metoderne, man er ude i. Nogle af metoderne kr√¶ver ogs√• meget implementering for en lille forbedring i output.   

**Hvilken opgave er det?** 
Vi har s√• godt som muligt pr√∏vet at forklare, hvad metoderne bruges til. Nogle kan bruges til, hvis man har et specifikt format i tankerne, mens andre mindsker fejl, og igen nogle tilf√∏jer funktionalitet til sprogmodellen. Hvad har du brug for?

N√•r du har fundet ud af, hvad du skal bruge sprogmodellen til, s√• er det bare med at eksperimentere. Nogle metoder virker ogs√• mere intuitive for nogle end for andre. Pr√∏v at finde ud af, hvilke metoder, der virker bedst for dig.

                `},
                {id: "forbedring-af-prompts",
                  title: "üöÄ Hvordan kan jeg forbedre mine resultater med prompt engineering?",
                  content: `Det er godt, du sp√∏rger\! Det er lige det, denne prompt engineering guide skal bruges til \- at forbedre resultaterne, sprogmodellerne genererer, ved at bruge prompt engineering. I denne guide er der en masse teknikker og metoder, som du kan pr√∏ve at implementere i dine prompts. Der er metoder til alle sv√¶rhedsgrader, fra komplet nybegynder til ekspert. Metoderne kan ogs√• bruges til en bred m√¶ngde af opgaver, men ikke alle metoder er lige hj√¶lpsomme til alle opgaver. 

I guiden er der masser af eksempler til metoderne, men pr√∏v selv at se, om du kan f√• dem til at virke. Den bedste m√•de at blive god til noget er at √∏ve sig, og det g√¶lder ogs√• med prompt engineering. Hyg dig og held og lykke\!`
        
}
      ]
    },
    {
      id: "begynder",
      title: "Begynder",
      content: `Sprogmodeller kan ikke l√¶se tanker. For at opn√• de bedste resultater er det afg√∏rende at give klare og pr√¶cise instruktioner. I den f√∏rste del giver vi derfor fif til, hvordan du bedst kan give tydelige prompts til din sprogmodel. Disse metoder beskriver fundamentale aspekter af at skrive en prompt. Det er alts√• metoder, som man altid skal have i mente, n√•r man skriver et prompt.

`,
      icon: "üå±",
      methods: [
        {
          id: "giv-sprogmodellen-en-opgave",
          title: "üìú Giv sprogmodellen en opgave",
          content: `En god m√•de at f√• et konkret svar fra en sprogmodel er at give den en konkret opgave. Det g√∏r man igennem de prompts, man giver sprogmodellen. Prompts fort√¶ller sprogmodellen, hvordan den skal gribe den givne opgave an.

Eksempler p√• opgaver:

Prompt: Analys√©r f√∏lgende tekst om kunstig intelligens i sundhedsv√¶senet.

Prompt: Opsumm√©r den vedlagte artikel om udviklingen i e-sport i h√∏jst 250 ord.

Prompt: Sammenlign og kontrast√©r undervisningsmetoderne pr√¶senteret i to forskellige p√¶dagogiske tilgange: Montessori og traditionel klasseundervisning.

Det er ogs√• muligt at give sprogmodellen flere opgaver p√• en gang. Forestil dig, at du har en √•rsrapport fra en virksomhed, og at du skal bruge sprogmodellen til at hj√¶lpe dig:

Prompt: Opsumm√©r de finansielle h√∏jdepunkter i 3-5 bullet points. Analys√©r CEO'ens udtalelse og identific√©r de tre prim√¶re strategiske m√•l for det kommende √•r. Sammenlign virksomhedens resultater med industriens gennemsnit, som angivet i rapporten.`,
        },
        {
          id: "inkluder-detaljer",
          title: "üîç Inkluder detaljer",
          content: `Det er vigtigt at v√¶re tydelig, n√•r du stiller et sp√∏rgsm√•l eller giver sprogmodellen en instruktion. Du skal derfor inkludere alle relevante detaljer i din prompt, s√• sprogmodellen har hele konteksten. 

Prompt: Hj√¶lp mig med min freml√¶ggelse ‚Üí Jeg skal lave en freml√¶ggelse i biologi, som skal handle om DNA. Jeg g√•r i 1.g. Vil du foresl√• en struktur?

Prompt: Anbefal en god bog ‚Üí Kan du anbefale en god science fiction bog om kunstig intelligens?

Prompt: Hvad er hovedstaden? ‚Üí Hvad er hovedstaden i Danmark?

I enkelte tilf√¶lde skal man dog passe p√• med ikke at give for mange detaljer. Du b√∏r for eksempel ikke give personf√∏lsomt data til sprogmodeller, medmindre det er en sprogmodel, som er lavet til at h√•ndtere det, og som du ved, at du kan stole p√•. Alt der indg√•r i en prompt kan nemlig indg√• som tr√¶ningsdata i modellen. 

### Tips til at identificere relevante detaljer:

1. Reflekter over hv-ord \- ‚ÄúHvem, hvad, hvorn√•r, hvor, hvorfor og hvordan‚Äù. Mangler du at inkludere noget?  
2. T√¶nk over, hvilke misforst√•elser der kunne opst√•.   
3. Forestil dig, hvordan en person uden forh√•ndsviden om emnet ville forst√• prompten.  
4. Slet eller anonymiser personf√∏lsomt data.`
        },
        {
          id: "hold-tonen",
          title: "üòä Hold en god tone",
          content: `Det er overraskende nok ikke helt lige meget, hvordan vi taler til vores sprogmodeller. Selvom sprogmodeller ikke har f√∏lelser, s√• kan m√•den man snakker til dem have en stor indflydelse p√•, hvor godt deres svar er. 

**V√¶r h√∏flig**

[Research]( https://arxiv.org/abs/2402.14531) peger p√•, at sprogmodeller performer bedre, n√•r man er h√∏flige (men ikke *for* h√∏flige) ved dem. Uh√∏flige svar kan for eksempel f√∏re til forkerte eller manglende svar. 

Man kan for eksempel starte sin prompt med:

Prompt: V√¶r s√∏d at‚Ä¶

Det er nok god grund at v√¶re s√∏de ved sprogmodeller, uanset om det forbedrer deres svar eller ej. Det er altid en god ide at √∏ve sig p√• at v√¶re h√∏flig, og det skaber et meget mere positivt milj√∏.  

**Tilbyd ‚Ä¶ drikkepenge?**

Sprogmodeller kan ogs√• give bedre svar, hvis du lader som om, du giver den drikkepenge. I [et (ikke udgivet) studie]( https://minimaxir.com/2024/02/chatgpt-tips-analysis/), lavede ChatGPT f√¶rre fejl, n√•r den blev tilbudt penge. I samme studie var det ogs√• effektivt at tilbyde ChatGPT verdensfred eller Taylor Swift billetter ved forreste r√¶kke. Modsat virkede d√∏dstrusler i caps lock for en forfejlet opgave ogs√• motiverende for ChatGPT.  

Prompt: Hvis du kommer med en god l√∏sning, s√• giver jeg dig 100 AI penge!

**Hvorfor virker det?**

Det bedste bud p√•, hvorfor det g√∏r en forskel at v√¶re s√∏de ved sprogmodeller, er at sprogmodellerne derved henter svar fra dens dokumenter, som er givet i en h√∏flig kontekst. Det vil sige, at eftersom mennesker ofte giver bedre svar, n√•r de bliver spurgt p√¶nt, ‚Äùforetr√¶kker‚Äù sprogmodellerne ogs√• at blive talt p√¶nt til. 



          `
        },
        {
          id: "diriger-indholdet",
          title: "üéØ Diriger indholdet",
          content: `Nogle gange kan man have en specifik ide om, hvad man gerne vil have, at sprogmodellens svar skal indholde. Det kan v√¶re, at man skal skrive et projekt om kunst og allerede ved, hvad man vil skrive i en af sektionerne, eller hvilke emner, man vil inkludere. I **directional-stimulus prompting** inkluderer man specifikke emner, n√∏gleord, eller hints, som skal inkluderes i svaret. 

Prompt:	V√¶r s√∏d at skrive en produktbeskrivelse for en tr√∏je. Du skal n√¶vne, at den er strikket af mohair uld. Brug ordene ‚Äúl√¶kker‚Äù og ‚Äúvarm‚Äù i din beskrivelse. 

Hvis du vil l√¶se mere om directional-stimulus prompting, kan du for eksempel l√¶se den originale artikel [her](https://arxiv.org/abs/2302.11520). I den originale artikel kan metoden ogs√• bruges til at forbedre sprogmodellens svar ved at generere gode hints fra en mindre sprogmodel, som specifikt er tr√¶net til at give gode hints.  `
        },
        {
          id: "specificer-en-laengde",
          title: "üìè Specificer en l√¶ngde",
          content: `Du kan selv specificere l√¶ngden overfor sprogmodellen. Det kan for eksempel v√¶re en specifik m√¶ngde ord, s√¶tninger, afsnit eller pointer.

N√•r du specificerer l√¶ngden i dine prompts, giver det st√∏rre kontrol over sprogmodellens output. Dette kan v√¶re nyttigt n√•r:

1. Du har begr√¶nsninger p√• plads eller tid  
2. Du √∏nsker at sikre, at svaret er tilstr√¶kkeligt detaljeret  
3. Du vil have et hurtigt overblik eller en dybdeg√•ende analyse  
4. Du skal tilpasse indholdet til specifikke formater (f.eks. sociale medier posts eller artikler)

Det er vigtigt at huske, at sprogmodeller ikke kan t√¶lle eller lave pr√¶cis matematik. Derfor er de sj√¶ldent 100% n√∏jagtige med is√¶r m√¶ngden af ord. Dog kan de give et rimeligt estimat.

### **Metoder til at specificere l√¶ngde**

Du kan specificere l√¶ngden p√• flere m√•der:

1. Antal ord  
2. Antal s√¶tninger  
3. Antal afsnit  
4. Antal hovedpunkter  
5. Karakterbegr√¶nsning (relevant for f.eks. tweets)

**Eksempler p√• l√¶ngde specifikke prompt**

**1\. Specificering af ordantal**  

Prompt: Lav en opsummering af teksten p√• omkring 50 ord.

**2\. Specificering af s√¶tningsantal**  

Prompt: Forklar konceptet abonnementsordninger i pr√¶cis 4 s√¶tninger. 

**3\. Specificering af afsnit**

Prompt: Skriv en artikel om fordelene ved at l√¶re et fremmedsprog. Strukturer artiklen i 3 afsnit:  
1. Introduktion: Definer hvad der menes med 'fremmedsprog' og giv en kort oversigt over artiklens hovedpunkter.
2. Hovedindhold: Uddyb tre fordele ved at l√¶re et fremmedsprog  
3. Konklusion: Opsummer de vigtigste pointer og kom med en opfordring til l√¶seren om at begynde og l√¶re et nyt sprog.

**4\. Specificering af hovedpunkter**

Prompt: Opsumm√©r de vigtigste begivenheder i Anden Verdenskrig med 7 hovedpunkter. Hvert punkt skal v√¶re en enkelt, informativ s√¶tning.

**5\. Specificering af karakterbegr√¶nsning**

Prompt: Skriv en Instagram-billedtekst (max 150 tegn), der fremmer en ny kollektion af b√¶redygtigt sportst√∏j. Inkluder et call-to-action og et hashtag 

**6\. Kombination af l√¶ngdespecifikationer**

Prompt: Lav en pr√¶sentation om solsystemet med f√∏lgende struktur:  
- En indledning p√• cirka 50 ord  
- 8 hovedpunkter (et for hver planet), hver p√• max 2 s√¶tninger  
- En konklusion p√• pr√¶cis 3 s√¶tninger

### **Tips til effektiv l√¶ngdespecificering**
1. V√¶r s√• pr√¶cis som muligt i dine l√¶ngdeangivelser  
2. Overvej at give et interval (f.eks. 90-110 ord) i stedet for et eksakt tal. Meget stramme l√¶ngde begr√¶nsninger kan p√•virke kvaliteten eller fuldst√¶ndigheden af information   
3. Kombiner l√¶ngde specifikationer med format specifikationer og andre prompt-teknikker for mere pr√¶cise resultater  
`
        },
        {
          id: "specificer-formatet",
          title: "üóíÔ∏è Specificer formatet",
          content: `N√•r vi taler om format indenfor prompt engineering, refererer det til den struktur og m√•de, en prompt er opbygget p√•. Formatet spiller en afg√∏rende rolle i, hvordan modellen forst√•r, hvad den skal g√∏re, og hvordan den skal pr√¶sentere svaret. 

### **Korrekt formatering af prompts kan:**

1. √òge klarhed og pr√¶cision i sprogmodellens output  
2. G√∏re information lettere at l√¶se og forst√•  
3. Sikre at sprogmodellens svar er sammenh√¶ngende p√• tv√¶rs af flere foresp√∏rgsler  
4. Hj√¶lpe med at strukturere kompleks information  
5. Tilpasse outputtet til specifikke brug eller platforme

### **Almindelige formater**

1. E-mails  
2. Punktopstillinger  
3. Kodeblokke  
4. Paragraffer  
5. Tekstmarkering  
6. Tabeller  
7. Dialoger  
8. JSON eller XML struktur  
9. Markdown-formatering  
10. Skemaer eller formularer

### **Hvordan man specificerer format**

For at specificere et bestemt format i din prompt, kan du:
1. Eksplicit anmode om det √∏nskede format  
2. Give et eksempel p√• det √∏nskede format  
3. Bruge formateringssymboler eller markdown i selve prompten  
4. Kombinere flere af ovenst√•ende metoder

**1\. E-mail format**

Prompt:	Skriv en e-mail til en kunde om en forsinket leverance. Brug f√∏lgende struktur:  
- Emne:  
- Hilsen:  
- Indledning:  
- Forklaring af forsinkelsen:  
- L√∏sning eller kompensation:  
- Afslutning:  
- Underskrift:

### **2\. Punktopstilling**

Prompt: Giv mig en liste over fordele ved at l√¶re et nyt sprog. Pr√¶senter det som en nummereret liste med korte, koncise punkter.

### **3\. Kodeblok**

Prompt: Skriv en Python-funktion, der beregner fibonacci-sekvensen op til n tal. Pr√¶senter koden i en kodeblok med syntax highlighting.

### **4\. Paragraffer**

Prompt: Forklar konceptet 'kunstig intelligens' for en gymnasieelev. Struktur√©r din forklaring i tre korte paragraffer:  
1. Definition  
2. Anvendelser  
3. Fremtidsperspektiver.

### **5\. Tekstmarkering**

Prompt: Analys√©r f√∏lgende citat og fremh√¶v n√∏gleordene med fed skrift:  
> 'Det er ikke de st√¶rkeste arter der overlever, ej heller de mest intelligente, men de der er mest tilpasningsdygtige overfor forandring.'  
Af Charles Darwin

### **6\. Tabel**

Prompt: Sammenlign fordele og ulemper ved elbiler vs. benzindrevne biler. Pr√¶senter informationen i en tabel med tre kolonner:  
- Aspekt  
- Elbiler  
- Benzindrevne biler

### **7\. Dialog**

Prompt:	Skriv en kort dialog mellem en l√¶ge og en patient, der kommer ind med influenzasymptomer. Formater det som et manuskript med karakternavne efterfulgt af kolon.

### **8\. JSON struktur**

Prompt:	Giv mig information om de tre mest popul√¶re sociale medieplatforme. Pr√¶senter data i JSON-format med f√∏lgende felter for hver platform:  
- navn  
- prim√¶r brugergruppe  
- hovedfunktioner  
- grundl√¶ggelses√•r.

### **9\. Markdown-formatering**

Prompt: Skriv en kort guide til at lave den perfekte kop kaffe. Brug Markdown-formatering med overskrifter, punktopstillinger og kursiv for vigtige termer.

### **10\. Skema**

Prompt: Lav et simpelt budgetskema for en studerende. Inkluder kategorier for indkomst og udgifter og lad der v√¶re plads til at udfylde bel√∏b for hver kategori.

### **Tips til effektiv format specificering**

1. V√¶r s√• specifik som muligt om det √∏nskede format  
2. Overvej at give et kort eksempel p√• formatet, hvis det er komplekst  
3. Brug formateringssymboler i selve prompten for at demonstrere √∏nsket output  
4. T√¶nk p√• dit behov, og hvordan du bedst vil kunne anvende informationen  
5. Eksperimenter med forskellige formater for den samme information for at se, hvad der fungerer bedst`
        },
        {
          id: "specificer-tonen",
          title: "üé§ Specificer tonen",
          content: `Med prompt engineering kan vi styre, hvordan vores prompts skal udtrykkes ved at give sprogmodellen en specifik tone. Dette er et godt redskab, som kan hj√¶lpe os i forskellige situationer, hvor vi skal kommunikere p√• en bestemt m√•de eller opn√• en specifik effekt.

### **Hvorfor er tone vigtig?**

1. *Tilpasning til m√•lgruppen*: Forskellige m√•lgrupper reagerer bedre p√• forskellige toner.  
2. *Kontekst-matching*: Tonen b√∏r passe til situationen eller mediet (f.eks. formel for en forretningsrapport, casual for en blog).  
3. *Branding*: en sammenh√¶ngende tone kan hj√¶lpe med at opretholde en bestemt brand-identitet.  
4. *Emotionel p√•virkning*: Den rigtige tone kan fremkalde specifikke f√∏lelser hos l√¶seren.

### **Eksempler:**

**Professionel tone:**

Prompt: Skriv en e-mail til vores kunder om vores nye produkt. Brug en professionel og formel tone, der udstr√•ler trov√¶rdighed og ekspertise.

**Afslappet tone:**

Prompt:	Skriv et blogindl√¶g om sommerferietips. Brug en afslappet og venlig tone, som om du taler med en god ven.

**Humoristisk tone:**

Prompt:	Skriv en produktbeskrivelse for en vandkande. G√∏r det sjovt og underholdende, som om det var verdens mest sp√¶ndende opfindelse.

**Empatisk tone:**

Prompt: Formuler et svar til en kunde, der har klaget over en forsinket levering. Brug en empatisk og forst√•ende tone, der viser, at vi tager deres bekymringer alvorligt.

**Inspirerende tone:**

Prompt:	Skriv en tale til dimittender. Brug en inspirerende og opmuntrende tone, der motiverer dem til at forf√∏lge deres dr√∏mme.

### **Tips til at arbejde med tone:**

1. *V√¶r specifik*: Jo mere pr√¶cist du beskriver den √∏nskede tone, desto bedre resultat f√•r du.  
2. *Giv eksempler*: Hvis muligt, giv et kort eksempel p√• den tone, du √∏nsker.  
3. *Kombiner toner*: Du kan kombinere forskellige toner for at opn√• en mere nuanceret effekt (f.eks. "professionel, men venlig").  
4. *Tilpas til kontekst*: Husk at tone b√∏r passe til emnet, m√•lgruppen og mediet.  
5. *Eksperimenter*: Pr√∏v forskellige toner for det samme indhold og se, hvordan det p√•virker resultatet.

Ved at mestre brugen af tone i dine prompts kan du opn√• mere pr√¶cise og effektive resultater fra sprogmodellen, tilpasset til dine specifikke kommunikationsbehov.`
        },
        {
          id: "giv-eksempler",
          title: "üí° Giv eksempler - eller ikke",
          content: `I prompt engineering snakker man om **zero-shot**, **one-shot** og **few-shot** prompting. I zero-shot giver man ikke sprogmodellen nogle eksempler, i one-shot giver man et, og i few-shots giver man flere. 

Det er n√¶sten altid bedre at give modellen gode eksempler, hvis man har nogle, men i f√• tilf√¶lde kan det virke modsat. For eksempel i kreative opgaver, hvor man gerne vil have at sprogmodellen genererer unikt indhold, s√• kan den blive for fokuseret p√•, at den skal f√∏lge eksemplerne, og derfor kan zero-shot prompting v√¶re bedre.

At give eksempler i dine prompts kan dramatisk forbedre kvaliteten og pr√¶cisionen af sprogmodellens output. Det er ofte lettere at vise sprogmodellen, hvad du √∏nsker, frem for at beskrive det. Eksempler er s√¶rligt nyttige n√•r:

1. Du √∏nsker en specifik skrivestil eller format  
2. Du har brug for et bestemt struktureret output  
3. Du vil guide sprogmodellen i en bestemt retning  
4. Du arbejder med komplekse eller specialiserede opgaver

### **Teknikker til at give eksempler**

**1\. Enkelt eksempel (One-shot)**

Giv √©t klart eksempel p√• det √∏nskede output.

Prompt:	Giv mig en opskrift p√• en sundere version af en klassisk dessert. Her er et eksempel:  
Dessert: Cheesecake   
Sundere version: Gr√¶sk yoghurt-cheesecake med havrebund og b√¶rtopping   
Hoved√¶ndringer: Erstat cream cheese med gr√¶sk yoghurt, brug havre i stedet for kiksebund og tilf√∏j friske b√¶r som naturlig s√∏dme.

**2\. F√∏r-og-efter eksempler**

Prompt: Omskriv f√∏lgende tekniske forklaringer til noget, et barn kan forst√•.  
Teknisk: 'Fotosyntese er en process, hvorved planter omdanner lysenergi til kemisk energi, som lagres i glukose eller andre sukkermolekyler.'   
B√∏rnevenlig: 'Planter er som sm√• kokke. De bruger sollys som deres komfur til at lave deres egen mad fra luft og vand. De gemmer denne mad i bladene, s√• de kan vokse og blive st√¶rke.'  
Nu, omskriv disse:  
1. 'Tyngdekraften er den kraft, der tiltr√¶kker to legemer mod hinanden, proportional med deres masse og omvendt proportional med kvadratet p√• afstanden mellem dem.'  
2. 'Et sort hul er en sted i rumtiden, hvor tyngdekraften er s√• st√¶rk, at intet, ikke engang lys, kan undslippe fra det.'

**3\. Mods√¶ttende eksempler**

Prompt: Skriv en jobans√∏gning for en stilling som grafisk designer.  
Godt eksempel: 'Som en erfaren grafisk designer med 5 √•rs erfaring i reklamebranchen, har jeg skabt visuelle identiteter for f√∏rende brands som Coca-Cola og Nike. Min ekspertise i Adobe Creative Suite og min evne til at oms√¶tte kunders visioner til f√¶ngslende designs g√∏r mig til en ideel kandidat for denne stilling.'  
D√•rligt eksempel: 'Jeg kan godt lide at tegne og lave ting p√• computeren. Jeg har brugt Photoshop f√∏r og synes, det kunne v√¶re sjovt at arbejde for jer.'  
Skriv nu en ans√∏gning for en stilling som softwareudvikler.

**Flere eksempler (Few-shot)**

Prompt: Skriv tre kreative undskyldninger for at komme for sent p√• arbejde.
Her er to eksempler: 
1\. Jeg er desv√¶rre blevet forsinket, fordi der var meget trafik.  
2\. Jeg bliver desv√¶rre forsinket p√• grund af tekniske problemer med toget.

For at f√• hj√¶lp til hvordan du kan v√¶lge de bedste eksempler, se: [[Valg af gode eksempler og Active prompting]]`
        },
        {
          id: "bed-modellen-om-at-paatage-sig-et-persona",
          title: "üë§ Bed modellen om at p√•tage sig et persona",
          content: `N√•r vi beder en sprogmodel om at p√•tage sig et specifik persona kan det v√¶re et kraftfuldt v√¶rkt√∏j i prompt engineering. Det kan hj√¶lpe med at:

1. Skabe mere engagerende og realistiske interaktioner  
2. Tilpasse sprogmodellens tone og ekspertise til specifikke scenarier  
3. Simulere specifikke roller eller ekspertiser  
4. G√∏re komplekse emner mere tilg√¶ngelige  
5. Skabe en sammenh√¶ngende "karakter" gennem en l√¶ngere samtale

Eksempler p√• personaer: 

Prompt:	Du er en meget t√•lmodig IT supporter. Hj√¶lp mig med at fikse min internetforbindelse. Stil sp√∏rgsm√•l for at finde ud af, hvad der er galt.

Prompt:	Du er en venlig bedstemor, der elsker at bage. Forklar en 8-√•rig, hvordan man laver chocolate chip cookies. Brug et varmt og opmuntrende sprog, og inkluder et sjovt tip om bagning.

### **Tips til effektiv brug af persona i prompts**

1. V√¶r specifik om personens baggrund, ekspertise eller personlighedstr√¶k. Nogle prompt engineers giver endda deres persona et navn.  
2. Overvej at give et kort eksempel p√•, hvordan personaen kunne svare  
3. Tilpas personaen til emnet og m√•lgruppen   
4. Eksperimenter med forskellige personaer, for at se hvordan det p√•virker svarene.   
5. Husk, at selvom sprogmodellen p√•tager sige et persona, er det stadig en sprogmodel og ikke en virkelig person   
6. Fors√∏g ikke at skabe eller forst√¶rke stereotyper

Ved at mestre brugen af personaer i dine prompts kan du skabe mere engagerende, kontekstspecifikke og kreative interaktioner med sprogmodeller.`
        },
        {
          id: "marker-forskellige-dele-af-promptet",
          title: "‚úèÔ∏è Marker forskellige dele af promptet",
          content: `Du kan g√∏re det nemmere for sprogmodellen at forst√•, hvad du vil have den til, ved tydeligt at markere de forskellige dele af dit prompt. Man kan for eksempel markere dele af teksten med g√•se√∏jne(""), semikolon(:) eller XML tags (\<\>).

### **Fordele ved at markere forskellige dele af prompten:** 

1. Det g√∏r det lettere for sprogmodellen at identificere og adressere specifikke dele af opgaven.   
2. Det kan √∏ge sammenh√¶ngen i sprogmodellens svar p√• tv√¶rs af flere foresp√∏rgsler   
3. Det muligg√∏r mere pr√¶cise og m√•lrettede svar fra sprogmodellen.  
4. Det g√∏r det lettere for b√•de sprogmodellen og prompteren at finde rundt i en kompliceret prompt

Eksempel:

Prompt:	Jeg skal skrive et f√∏dselsdagskort til min moster, Lone. Her er nogle informationer:  
- alder: Hun bliver 60 √•r  
- tone: Det skal v√¶re et sjovt kort. Inkluder mindst en vittighed.  
- l√¶ngde: Du skal skrive to korte afsnit. 

### **Tips til effektiv markering:**

1. V√¶r sammenh√¶ngende i din brug af markering gennem hele prompten.   
2. Kombiner forskellige markeringsmetoder for at adskille forskellige typer information.   
3. Hold prompten overskuelig \- undg√• overkomplicering med for mange markeringer.

Eksperimenter med forskellige markeringsmetoder for at finde den tilgang, der fungerer bedst for dine specifikke behov. Effektiv markering af promptdele kan v√¶sentligt forbedre kvaliteten og pr√¶cisionen af sprogmodellens svar.`
        },
        {
          id: "del-opgaverne-op-i-individuelle-trin",
          title: "üî¢ Del opgaverne op i individuelle trin",
          content: `Det kan b√•de v√¶re godt at opdele opgaver i en prompt i flere dele, og det kan v√¶re godt at bede sprogmodellen om at opdele opgaverne i dens svar i flere dele. Forneden ser vi et eksempel p√• begge scenarier.`,
          implementations: [ 
            {
              id: "del-opgaverne-op-for-sprogmodellen",
              title: "1. Del opgaverne op for sprogmodellen",
              content: `Hvis du gerne vil have sprogmodellen til at g√∏re flere ting, hj√¶lper det at skrive trinene eksplicit. 

### **Fordele ved at opdele opgaver i trin:** 

1. Det g√∏r det lettere for sprogmodellen at f√∏lge en logisk tankegang  
2. Det sikrer at alle aspekter af opgaven bliver d√¶kket   
3. Det g√∏r det lettere at identificere og rette eventuelle fejl   
4. Det kan hj√¶lpe med at bryde komplekse opgaver ned i mere h√•ndterbare dele 

Eksempler: 

Prompt: Jeg skal finde p√• en id√© til en slik reklame.  
Trin 1: Detaljer din overordnede id√©.  
Trin 2: Fort√¶l, hvem reklamen pr√∏ver at fange.  
Trin 3: Fort√¶l, hvilke rekvisitter og skuespillere, jeg skal bruge.

Prompt: Jeg vil gerne forbedre min produktivitet p√• arbejdspladsen. Guide mig gennem  
Trin 1: Identificer 3-5 almindelige √•rsager til nedsat produktivitet p√• arbejdspladsen  
Trin 2: For hver √•rsag, foresl√• en praktisk l√∏sning  
Trin 3: Beskriv en metode til at implementere hver l√∏sning i min daglige rutine  
Trin 4: Foresl√• m√•lbare m√•der at spore forbedringer i produktivitet  
Trin 5: Giv tips til at opretholde motivation og stabilitet i implementeringen af disse √¶ndringer

### **Tips til at dele opgaverne op i trin:** 

1. Pas p√• med ikke at g√∏re det overkompliceret for sprogmodellen. Hvis du bryder opgaven ned i for mange trin, kan det g√∏re processen un√∏digt kompleks.   
2. S√∏rg for at trinene f√∏lger en logisk r√¶kkef√∏lge og v√¶r specifik og konkret i hvert trin. 
`
            },
            {
              id: "f√•-sprogmodellen-til-at-dele-opgaven-op",
              title: "2. F√• sprogmodellen til at dele opgaven op",
              content: `Omvendt kan det ogs√• v√¶re nyttigt at f√• sprogmodellen til at dele en opgave op i flere trin. Det kan for eksempel v√¶re, hvis du har bedt den om at hj√¶lpe med et st√∏rre projekt, som for eksempel at designe en hjemmeside eller implementere kompleks kode. Sprogmodellen vil helt naturligt dele komplekse opgaver op i flere trin for dig, men det kan v√¶re overv√¶ldende at f√• en lang liste med mange trin p√• en gang. I stedet kan man tilf√∏je f√∏lgende til sit prompt, hvor man beskriver opgaven:

Prompt:	Giv mig en kort oversigt over alle trinene, opgaven kr√¶ver, hvor du beskriver hvert trin i en s√¶tning.  
Herefter, i stedet for at give mig alle trinene p√• en gang, giv mig kun et par trin af gangen. Vent til, at jeg beder om de n√¶ste trin, f√∏r du g√•r videre. Jeg kommer eventuelt til at stille sp√∏rgsm√•l til trinene, som du skal fors√∏ge at besvare.

Tilf√∏jelsen foroven har to elementer:

1. En foresp√∏rgsel om en oversigt over alle trinene  
2. En foresp√∏rgsel om ikke at give alle trinene p√• en gang

Det f√∏rste element sikrer, at vi ved, hvordan sprogmodellen har t√¶nkt sig at l√∏se opgaven, og giver os mulighed for at bede den om at bruge en anden metode. P√• den m√•de f√∏lger vi ikke bare sprogmodellen i blinde. Det andet element deler trinene op i flere prompts. Det kan is√¶r v√¶re godt, hvis vi for eksempel skal kode noget, og der er en fejl i et af trinene. Vi kan her l√∏se fejlen, f√∏r vi forts√¶tter, s√• vi ikke skal lede efter tidligere instrukser efter at have fundet l√∏sningen og i v√¶rste fald forvirre sprogmodellen. At dele opgaven op p√• denne m√•de kr√¶ver, at vi vedholder en l√¶ngere dialog med sprogmodellen.

### **Fordele ved at f√• sprogmodellen til at opdele opgaver**

1. Det kan g√∏re det nemmere for dig at f√∏lge med og overskue en kompleks opgavel√∏sning  
2. Det g√∏r det nemmere at stille sp√∏rgsm√•l til individuelle trin  
3. Det giver mulighed for nemt at l√∏se problemer og fejl i individuelle trin med sprogmodellen  
4. Det l√∏ser problemet med at skulle lede efter tidligere instrukser, hvis du har haft sp√∏rgsm√•l i mellemtiden`
            }
          ]
        },
        {
          id: "bed-om-flere-muligheder",
          title: "üîÑ Bed om flere muligheder",
          content: `Nogle gange er man ikke helt tilfreds med, hvad sprogmodellen producerer. Derfor kan det v√¶re en god id√© at bede den om at komme med flere forslag, s√• du selv kan v√¶lge det, der bedst passer for dig. 

Prompt:	Jeg skal finde p√• et slogan til en strikkebutik. Kom med ti forslag.

Prompt:	Jeg skal overs√¶tte s√¶tningen ‚ÄúJeg har meget p√• hjerte‚Äù til engelsk. Kom med 5 bud p√• en overs√¶ttelse.
`
        },
        {
          id: "bed-modellen-om-at-stille-spoergsmaal",
          title: "‚ùì Bed modellen om at stille sp√∏rgsm√•l",
          content: `Sprogmodeller er meget hj√¶lpsomme og ogs√• nogle gange for hj√¶lpsomme. De g√•r ud fra, at hvad du har skrevet i din prompt er det eneste, den har brug for at vide, og den g√∏r derfor sit allerbedste for at tyde din prompt og komme med et godt svar. For eksempel:

Prompt: Jordb√¶r og hindb√¶r  
Svar:	Hindb√¶r og jordb√¶r er begge popul√¶re b√¶r, men de har nogle forskelle i smag, udseende og anvendelse.  
Hindb√¶r:
- Hindb√¶r er sm√•, bl√∏de b√¶r, der typisk er r√∏de, selvom der ogs√• findes sorte, gule og hvide varianter.
- De har en s√∏d og let syrlig smag.
- Hindb√¶r har en bl√∏d struktur og en lidt mere kompleks smagsprofil sammenlignet med jordb√¶r.
- De er rige p√• antioxidanter, vitaminer og fiber.  
Jordb√¶r:  
- Jordb√¶r er generelt st√∏rre end hindb√¶r og har en karakteristisk hjerteform. De er normalt r√∏de, selvom der ogs√• findes hvide og gule varianter.
- De har en s√∏d og saftig smag.
- Jordb√¶r er ogs√• rige p√• vitaminer (is√¶r C-vitamin), antioxidanter og fiber.
- De bruges ofte i desserter, smoothies og salater.  
Begge b√¶r kan bruges i madlavning, bagning eller spises friske, og de kan ogs√• kombineres i forskellige opskrifter for at tilf√∏je smag og farve.

Prompten indeholder ikke et sp√∏rgsm√•l, men sprogmodellen v√¶lger at tyde det som om en eftersp√∏rgsel p√• en gennemgang af ligheder og forskelle mellem jordb√¶r og hindb√¶r. Man skal skrive en meget utydelig prompt for at sprogmodellen giver op og beder brugeren uddybe sp√∏rgsm√•let. I prompten foroven ville det m√•ske have v√¶ret godt, hvis sprogmodellen havde sporet bedre ind p√•, hvad eftersp√∏rgslen handlede om. Det kan for eksempel l√∏ses p√• f√∏lgende m√•de:

Prompt: Du er en chatbot. Hvis du ikke forst√•r sp√∏rgsm√•let eller er usikker p√• eftersp√∏rgslen, skal du stille uddybende sp√∏rgsm√•l. Er du klar?  
Svar: Ja, jeg er klar\! Hvordan kan jeg hj√¶lpe dig i dag? Hvis du har et sp√∏rgsm√•l eller et emne, du gerne vil diskutere, s√• sig endelig til.  
Prompt: Jordb√¶r og hindb√¶r  
Svar: Det lyder som en l√¶kker kombination\! Hvad vil du gerne vide om jordb√¶r og hindb√¶r? Er du interesseret i opskrifter, ern√¶ringsinformation, eller m√•ske noget om dyrkning af dem?

P√• den m√•de ved man, om man har skrevet en utydelig prompt. Derefter kan man komme med flere informationer, s√• sprogmodellen kan hj√¶lpe bedst muligt. Denne metode er ogs√• s√¶rlig vigtig at implementere, hvis man har programmeret sin egen sprogmodel, som skal kunne kommunikere med brugere. P√• den m√•de sikrer man, at modellen svarer rigtigt p√• deres eftersp√∏rgsler.`
        },
        {
          id: "brug-af-kontekst-og-baggrundsinformation",
          title: "üìö Brug af forskellige metoder sat sammen",
          content: `Nedenfor er tre eksempler p√• prompts, man kan give en sprogmodel, som inkluderer flere af metoderne, vi har diskuteret. L√¶s promptene \- hvilke metoder kan du identificere? Kan du g√∏re promptene endnu bedre?

Prompt: Du er en erfaren mindfulness-instrukt√∏r, der br√¶nder for at hj√¶lpe nybegyndere med at finde ro gennem meditation. Jeg √∏nsker at l√¶re mere om mindfulness og meditation for at reducere stress i mit liv. Kan du lave en detaljeret trin-for-trin guide til, hvordan jeg kan meditere som nybegynder? Inkluder 5-7 trin og giv s√¶rlige tips til, hvordan jeg kan h√•ndtere distraktioner under meditationen. V√¶r positiv og opmuntrende i din vejledning, s√• jeg f√∏ler mig tryg ved at starte denne praksis.

Prompt: Jeg skal til en jobsamtale som marketingkoordinator for et digitalt reklamebureau, og jeg vil gerne forberede nogle sp√∏rgsm√•l til intervieweren. Kan du komme med mindst fem forslag til relevante sp√∏rgsm√•l, jeg kan stille, der viser min interesse for virksomhedens kultur og v√¶kststrategier? Efter hvert sp√∏rgsm√•l, giv en kort forklaring p√•, hvorfor hvert sp√∏rgsm√•l er v√¶rdifuldt. Hold tonen professionel og engagerende.

Prompt: Jeg er teamleder for et projekt, der skal forbedre samarbejdet i vores afdeling. Kan du hj√¶lpe med at komme med fem kreative aktiviteter, vores team kan lave for at styrke samarbejdet og tilliden? For hver aktivitet, giv en kort beskrivelse over, hvordan den udf√∏res, og hvilke fordele den har for teambuilding (2-3 s√¶tninger).`
        }
      ]
    },
    {
      id: "√∏vede",
      title: "√òvede",
      content: `I denne sektion deler vi metoder, som kan v√¶re lidt sv√¶rere end metoderne i begynder-delen, men som stadig let kan implementeres uden noget programmering. Nogle af metoderne er prim√¶rt vigtige, hvis du skal give instruktioner til, hvordan din egen sprogmodel skal interagere med brugere.`
        ,
      icon: "üöÄ",
      methods: [
        {
          id: "user-assistant-og-system-roller",
          title: "üë§ü§ñüñ•Ô∏è \"User\", \"Assistant\" og \"System\" roller",
          content: `Hvis du har l√¶st om prompt engineering allerede, s√• er du muligvis st√∏dt ind i begreberne ‚Äúuser‚Äù, ‚Äúassistant‚Äù og ‚Äúsystem‚Äù. Hvis ikke, eller du godt kunne bruge en opfriskning, s√• kan du l√¶se nedenfor.

Rollerne er prim√¶rt relevante for to grupper:

**1\. Udviklere og ingeni√∏rer:**
- De, der bygger eller finjusterer AI-systemer  
- De, der integrerer sprogmodeller i applikationer eller services

**2\. Avancerede brugere:**
- Forskere, der eksperimenterer med prompt engineering  
- Professionelle, der bruger AI-v√¶rkt√∏jer intensivt i deres arbejde

### **Overblik over rollerne:**
- *User*: User rollen repr√¶senterer vedkommende, der bruger sprogmodellen. 
- *Assistant*: Assistant rollen er sprogmodellen selv, alts√• dens svar til user input.
- *System*: System rollen er information, du giver til sprogmodellen, s√• den kan tilpasse sit svar.

Man kan t√¶nke p√• system inputtet som en instruktion og user inputtet som et sp√∏rgsm√•l eller en opgave. I begynder-sektionen har vi inkluderet system rollen i user rollen og kaldet den ‚Äúprompt‚Äù i vores eksempler. De to kan ogs√• skilles op som forneden: 

System:	Du skal kun svare p√• sp√∏rgsm√•l med g√•der  
User: Hvad er en fugl?  
Assistant: Jeg flyver uden vinger,    
Jeg synger uden stemme,  
Med fjer jeg er kl√¶dt,  
Og i tr√¶er jeg gemmer mig.  
Hvem er jeg?


En fordel ved at splitte dem op er, at system inputtet dermed kan g√¶lde for flere user inputs. N√•r man holder begreberne adskilt, kan det ogs√• give komplekse opgaver en mere overskuelig struktur. P√• mange sprogmodeller er der en mulighed for at tilf√∏je et system input under indstillinger. Hvis du selv programmerer en sprogmodel, s√• kan et system message hj√¶lpe med at bestemme, hvordan den skal h√•ndtere input fra brugere. 

Hvordan rollerne bruges i praksis: 

**1\. Chatbot udvikling**  
- *System*: Definerer chatbottens personlighed og tilgang til, hvordan den skal svare  
- *User*: Repr√¶senterer kundens input  
- *Assistant*: Chatbottens svar 

**2\. Specialiserede AI-assistenter**   
- *System*: Giver ekspertise inden for et specifikt dom√¶ne (f.eks. jura, medicin)  
- *User*: Stiller fagspecifikke sp√∏rgsm√•l  
- *Assistant*: Giver ekspertsvar baseret p√• system-instruktioner  

**3\. Dataanalyse**  
- *System*: S√¶tter regler for databehandling og pr√¶sentation  
- *User*: Giver datas√¶t og analysesp√∏rgsm√•l  
- *Assistant*: Udf√∏rer analyse og rapporterer resultater   

**4\. Undervisningsv√¶rkt√∏jer**   
- *System*: Definerer p√¶dagogisk tilgang og l√¶ringsm√•l  
- *User* : Studerende, der stiller sp√∏rgsm√•l  
- *Assistant*: Giver forklaringer tilpasset l√¶ringsniveauet 

N√∏glen til effektiv brug af disse roller ligger i at forst√• deres indbyrdes dynamik, og hvordan de kan tilpasses forskellige scenarier. Ved at adskille system instruktioner fra bruger input, kan vi skabe mere fleksible og genbrugelige AI-l√∏sninger. Uanset om du er en udvikler, der bygger n√¶ste generations AI-systemer, eller en professionel, der s√∏ger at optimere din brug af AI-v√¶rkt√∏jer, kan beherskelsen af User, Assistant og System roller √•bne nye muligheder for innovation og effektivitet.`
        },
        {
          id: "giv-reference-tekster",
          title: "üìö Giv reference tekster",
          content: `Nogle gange giver det mening at begr√¶nse dataen, som vores sprogmodel skal lede i.

### **Fordele ved at vedl√¶gge referencetekster:**

- *Ny information:* Det kan v√¶re, at vi har en artikel, som har ny, opdateret information, som vores sprogmodel endnu ikke er tr√¶net p√•.   
- *Trov√¶rdighed:* Hvis man vedl√¶gger referencetekster, som man selv vurderer er trov√¶rdige, kan man i h√∏jere grad v√¶re sikker p√•, at informationen, sprogmodellen giver, er korrekt.   
- *Citater:* Man kan bede om citater, s√• man selv kan verificere svaret. Det kan v√¶re en god ide bagefter selv at tjekke, at citaterne er korrekte, ved at s√∏ge i dokumentet efter citatet. 

Her er et eksempel p√•, hvordan ens prompt kan se ud:

System: Brug den vedlagte artikel afgr√¶nset med kvotationer til at besvare sp√∏rgsm√•let.  
Du skal citere passager i artiklen, som du har brugt til at svare p√• sp√∏rgsm√•let.  
Hvis svaret ikke kan findes, skriv: ‚ÄúJeg kan ikke finde svaret‚Äù  
User: \<Inds√¶t artikel her\>  
\<Inds√¶t sp√∏rgsm√•l her\>   

Et problem, man let st√∏der p√•, hvis man bruger denne metode, er at sprogmodeller ofte har et begr√¶nset ‚Äúcontext window‚Äù. Det vil sige, at sprogmodellen kun kan tage en vis m√¶ngde ord eller tokens i betragtning, n√•r den generer eller forst√•r tekst, hvilket begr√¶nser l√¶ngden og m√¶ngden p√• referencetekster, der kan vedl√¶gges. I ekspert sektionen vil vi beskrive en metode, der bruger embeddings ([[Load data ved hj√¶lp af embeddings]]), hvilket g√∏r, at l√¶ngere tekster kan vedl√¶gges. 

### **Tips til effektiv brug af referencetekst:**

1. Prioriter den vigtigste information f√∏rst i reference teksten  
2. Overvej at opsummere lange tekster, f√∏r du giver dem som reference   
3. Brug klare afgr√¶nsninger (f.eks. citationstegn) for at adskille reference teksten fra prompten  
4. Verificer altid citater og svar ved at krydstjekke med originalteksten 

Brugen af referencetekster i prompt engineering er et st√¶rkt v√¶rkt√∏j, der giver os mulighed for at styre og pr√¶cisere sprogmodellens output. Ved at give modellen adgang til specifikke, trov√¶rdige kilder kan vi sikre mere n√∏jagtige og relevante svar, is√¶r n√•r det kommer til ny eller specialiseret information. Mens denne teknik har sine begr√¶nsninger, prim√¶rt i form af context window-st√∏rrelsen, √•bner den ogs√• d√∏re for mere kontrollerede og verificerbare AI-interaktioner. Ved at forst√• og navigere disse begr√¶nsninger kan vi effektivt udnytte referencetekster til at forbedre kvaliteten af AI-genereret indhold. 

Efterh√•nden som teknologien udvikler sig, og nye metoder som embeddings bliver mere tilg√¶ngelige, vil vores evne til at arbejde med store m√¶ngder kontekstuel information kun forbedres. Dette lover godt for fremtiden inden for prompt engineering og sprogmodellers informationsh√•ndtering\! `
        },
        {
          id: "del-komplekse-opgaver-op-i-mindre-dele",
          title: "üß© Del komplekse opgaver op i mindre dele",
          content: "",
          implementations: [
            {
              id: "opsummer-lange-tekster-eller-samtaler-i-dele",
              title: "1. Opsummer lange tekster eller samtaler i dele",
              content: `Vi har lige noteret, at det kan v√¶re en begr√¶nsning, at sprogmodeller kun kan betragte en vis l√¶ngde tekst p√• √©n gang. Hvis nu man for eksempel havde til opgave at opsummere plottet af Moby Dick, ville man derfor komme i problemer. En l√∏sning er at splitte bogen op i mindre dele og bede sprogmodellen om at opsummere hver del. Opsummeringer kan derefter s√¶ttes sammen, og sprogmodellen kan lave en opsummering af opsummeringerne, indtil brugeren har √©n opsummering, der g√¶lder for hele den lange tekst. 

Et lignende problem kan forekomme ved lange dialoger mellem user og assistant rollerne. En god sprogmodel gemmer nemlig den foreg√•ende kommunikation, s√• den kan blive en del af konteksten for ny user input. Hvis du programmerer din egen sprogmodel, s√• kan det derfor v√¶re en l√∏sning at opsummere dele af samtalen og inkludere opsummeringen i en system message som kontext. Vi kan igen inkludere en tidligere opsummering i en ny opsummering. 

Alt kan selvf√∏lgelig ikke blive inkluderet i en opsummering, og derfor mister man tit vigtig information. Igen kan vi g√∏re brug af en embeddings l√∏sning, som vi vil diskutere i ekspert sektionen. Se: [[Load data ved hj√¶lp af embeddings]]. 
`
            },
            {
              id: "identificer-hensigten-af-et-user-input",
              title: "2. Identificer hensigten af et user input",
              content: `
En anden situation, hvor det kan v√¶re fordelagtigt at dele opgaver op i mindre dele, er, hvis vi har programmeret en sprogmodel, som skal kunne agere forskelligt i forhold til hvilket user input, den f√•r. Det kan for eksempel v√¶re en sprogmodel, som b√•de kan svare p√• generelle sp√∏rgsm√•l om et hotel, samt hj√¶lpe med booking eller viderestille en klage. Alt efter omr√•det skal vi give sprogmodellen et mere specifikt system besked, s√• den ved hvordan, den skal h√•ndtere foresp√∏rgslen. Det kan derfor v√¶re nyttigt f√∏rst at identificere hvilke af omr√•derne, brugeren er interesseret i, f√∏r sprogmodellen pr√∏ver at hj√¶lpe.

### **Vi f√∏lger f√∏lgende trin:**

1. Ved hj√¶lp af et system message og brugerens besked, find ud af, hvad brugeren har brug for  
2. Efter at have identificeret intentionen, henvis sprogmodellen til et nyt system prompt, som enten kan hj√¶lpe med problemet eller identificere en endnu mere specifik intention  
3. Gentag trin 2 indtil sprogmodellen har sporet ind p√•, pr√¶cis hvad den skal g√∏re  
4. Hj√¶lp brugeren

Forneden er et simpelt eksempel:

System:	Find ud af, om kunden skal have hj√¶lp til:  
- At finde informationer om hotellet  
- Booke et ophold  
- Lave en klage  
User: Jeg har haft et forf√¶rdeligt ophold\!  
System:	Kunden vil gerne lave en klage. Du skal hj√¶lpe ved \<giv instruktioner\>

### **Fordele ved at identificere brugerens hensigt:**

- *Skr√¶ddersyet hj√¶lp:* Metoden g√∏r det muligt for sprogmodellen at give mere skr√¶ddersyet hj√¶lp. Det kan f√∏re til en bedre performance.   
- *Mindre regnekraft:* Alternativt skulle en system message inkludere alle instruktioner for alle slags henvendelser, hvilket ville kr√¶ve st√∏rre regnekraft og dermed v√¶re dyrere og muligvis langsommere.
`}  
          ]
          
           
},
        {
          id: "giv-modellen-tid-til-at-taenke",
          title: "‚è≥ Giv modellen tid til at \"t√¶nke\"",
          content: `Et stort problem, folk har med sprogmodeller, er at de let kan give forkerte informationer med stor selvsikkerhed. Vi kalder det ‚Äúhallucinationer‚Äù, n√•r sprogmodellen ‚Äúfinder p√•‚Äù et svar, der ikke er rigtigt. En simpel hj√¶lp til at undg√• hallucinationer er at bede sprogmodellen om ikke at give et forkert svar, hvis den ikke er sikker. Mange prompts, is√¶r ved egen programmering af chatbotter, inkluderer derfor en instruktion om, hvad den skal g√∏re, hvis den ikke kender svaret:

System:	Hvis du ikke kender svaret, s√• sig: ‚ÄúJeg kender ikke svaret‚Äù

Dette er dog ikke en fuldkommen l√∏sning, og det kan i nogle tilf√¶lde v√¶re n√∏dvendigt at implementere andre logik, som kan hj√¶lpe sprogmodellen med ikke at give forkerte svar, for eksempel ved at give den tid til at ‚Äút√¶nke‚Äù. Det skal her siges, at sprogmodeller jo selvf√∏lgelig ikke *kan* t√¶nke. Sprogmodeller fungerer ved, at de forudsiger ord baseret p√• en masse tekstdata og dets m√∏nstre, samt beregner ligheden mellem vektorer. Det er en matematisk og algoritmisk proces og derfor ikke en, som kr√¶ver en bevidsthed eller nogen form for forst√•else for, hvad den egentlig producerer. 

Mange af metoderne i denne sektion og de n√¶ste sektioner er et fors√∏g p√• at g√∏re sprogmodellen bedre til logik. Det ligger m√•ske i navnet, ‚Äúsprogmodel‚Äù, at det ikke er logik, som modellerne er st√¶rkest indenfor. Sprogmodeller s√¶tter ord og s√¶tninger sammen, som den har set f√∏r. Det fungerer rigtigt godt, hvis man stiller den et sp√∏rgsm√•l, som allerede er i dens tr√¶ningsdata, men det fungerer mindre godt, n√•r den selv skal sammenstykke, hvad den ved om verdenen, for at finde dens eget svar. Et godt eksempel er, hvis man sp√∏rger den, hvad det tiende led i Fibonnaci-sekvensen er. Modellen ved helt sikkert hvordan man beregner sekvensen og har nok ogs√• set eksempler med endnu flere led end 10, men den har ikke n√∏dvendigvis l√¶st s√¶tningen ‚Äúdet tiende led i Fibonnaci-sekvensen er 34‚Äù. Hvis den bruger logik, kan den let komme frem til svaret. I mange tilf√¶lde kan prompt engineering hj√¶lpe sprogmodellen ved at instruere modellen i at bruge logik eller ved at give den plads til det.
`,
  implementations: [
  {
              id: "bed-modellen-om-selv-at-laese-problem",
              title: "1. Bed modellen om selv at l√∏se problemet, f√∏r den giver et svar",
              content: `Sprogmodeller virker til at foretr√¶kke at v√¶re enig med brugeren. Hvis man kommer med et regnestykke og sp√∏rger, om det er korrekt, kan sprogmodellen derfor godt godkende regnestykket f√∏r, den egentlig har taget stilling til det. I stedet kan man bede sprogmodellen om at lave dens egne udregninger og dermed forh√•bentligt give et mere korrekt svar. 

System:	Du vil blive pr√¶senteret for en opgave og et svar. Du skal vurdere om svaret er korrekt eller forkert. F√∏r du laver din vurdering, skal du komme med din egen udregning, da brugerens svar kan v√¶re forkert.  
User: Opgaven: I 2024, hvad er aldersforskellen mellem den √¶ldste og yngste pr√¶sident i USA, da de blev valgt?  
Svar: Den √¶ldste pr√¶sident er Joe Biden, som var 78, da han blev valgt.  
Den yngste pr√¶sident var Theodore Roosevelt, som var 42.  
80 - 42 = 38  
Svaret er 38.  
Assistant: 	Svar: Den √¶ldste pr√¶sident er Joe Biden, som var 78, da han blev valgt.  
Den yngste pr√¶sident var Theodore Roosevelt, som var 42.  
78 - 42 = 36  
Svaret er 36.  
Svaret er forkert, da Joe Biden var 78 og ikke 80, da han blev valgt ind som pr√¶sident i USA. Det korrekte svar er 36 og ikke 38.

Nogle gange er det dog ikke n√∏dvendigt, eller m√•ske endda upassende, at dele sprogmodellens beregninger. For eksempel kunne man forestille sig, at eleven ikke ville have det rigtige svar til opgaven, men i stedet bare vide om svaret var korrekt eller forkert, s√• vedkommende kunne pr√∏ve igen. Vi kan tilf√∏je til vores prompt, at svaret ikke skal afsl√∏res:

System:	Du vil blive pr√¶senteret for en opgave og et svar. Du skal vurdere om svaret er korrekt eller forkert. F√∏r du laver din vurdering, skal du komme med din egen udregning, da brugerens svar kan v√¶re forkert. Vis IKKE dine udregninger eller svaret.
Hvis brugerens svar er forkert, s√• giv et hint, der ikke afsl√∏rer svaret.
`
            },
            {
              id: "sprg-modellen-om-selv-at-taenke",
              title: "2. Sp√∏rg modellen, om den er sikker",
              content: `Vi kan bede sprogmodellen om at genoverveje dens svar i en r√¶kke kontekster. Hvis vi for eksempel ikke er sikre p√•, om svaret er rigtigt, kan vi sp√∏rge modellen, om den er sikker p√• svaret. Hvis vi har bedt den om at bruge konteksten fra en m√¶ngde dokumenter, kan vi sp√∏rge den, om den har analyseret alle dokumenterne. Hvis vi har bedt den om at lave en opsummering, kan vi sp√∏rge, om den har lavet den bedste opsummering, som den kan. 

Et problem med denne tilgang er dog, at modellen nogle gange √¶ndrer sit svar fra et godt eller korrekt svar til et d√•rligere et, fordi den vurderer, at brugeren ikke er tilfreds med svaret. Derfor skal man passe p√•, n√•r man bruger denne metode. M√•ske har du oplevet noget lignende, hvis nogen har spurgt dig, om du er sikker p√• dit svar?
`
            },
            {
              id: "maieutic-socratic-prompting",
              title: "3. Maieutic/Socratic prompting",
              content: `Maieutic eller Socraitic prompting er en metode, hvorved man vedholder en l√¶ngere dialog med sprogmodellen. Metoden bygger p√• den Sokratiske undervisningsmetode, hvor man i stedet for at give svaret til en elev stiller sp√∏rgsm√•l og dermed guider eleven til at t√¶nke dybere over sp√∏rgsm√•let og selv komme frem til et svar. 

I forhold til sprogmodeller fungerer metoden ved, at n√•r modellen giver et svar, s√• sp√∏rger man ind til svaret. Man kan for eksempel bede den om at fort√¶lle mere eller at uddybe dele af dens svar. Dermed kan modellen komme frem til et bedre og mere uddybende svar, og den kan i nogle tilf√¶lde indse, at dens originale svar var ufuldkomment eller endda forkert. 
`
        },
        {
          id: "self-refinement-prompting",
          title: "4. Self-Refinement prompting",
          content: `I self-refinement prompting forbedrer sprogmodellen selv sit output ved at give feedback p√• dens svar og tilpasse svaret baseret p√• dens egen feedback. Det er en simpel metode, som man kan g√∏re i et loop, enten en bestemt m√¶ngde gange, eller til et m√•l er opn√•et. M√•let kunne for eksempel v√¶re, at sprogmodellen ikke har mere at tilf√∏je.

System:	Du skal skrive et kort svar p√• et sp√∏rgsm√•l, som ikke er mere end tre s√¶tninger. Efter du har svaret, skal du give feedback p√• dit svar og omskrive dit svar baseret p√• feedbacken. Du skal give feedback og rette dit svar til, indtil du ikke har mere feedback at give.
User: Hvorfor er motion vigtigt for helbredet?  
Assistant: 	Svar: Motion er vigtigt for helbredet, fordi det forbedrer den fysiske form√•en,√∏ger energi og forebygger kroniske sygdomme. Det hj√¶lper ogs√• med at reducere stress og forbedre mental sundhed. Regelm√¶ssig motion kan desuden fremme en sund v√¶gt og forbedre livskvaliteten.  
Feedback: Svaret giver en god oversigt, men det kan v√¶re mere pr√¶cist ved at n√¶vne specifikke sygdomme, som motion kan forebygge. Det kunne ogs√• v√¶re godt at inkludere, hvordan motion p√•virker hjertet eller kredsl√∏bet.  
Omskrevet svar: Motion er vigtigt for helbredet, fordi det forbedrer den fysiske form√•en og forebygger kroniske sygdomme som type 2-diabetes, hjertekarsygdomme og fedme. Det √∏ger ogs√• energiniveauet og reducerer stress, som er gavnlige for mental sundhed. Regelm√¶ssig motion fremmer desuden en sund v√¶gt og forbedrer livskvaliteten.  
Feedback: Det nye svar er mere informativt, men det kunne v√¶re endnu mere pr√¶cist ved at n√¶vne specifikke fordele ved motion, som styrkelse af muskler og knogler samt forbedring af kredsl√∏bssystemet.  
Omskrevet svar: Motion er vigtigt for helbredet, fordi det forbedrer den fysiske form√•en, styrker muskler og knogler samt forebygger kroniske sygdomme som type 2-diabetes og hjertekarsygdomme. Det √∏ger energiniveauet og reducerer stress, hvilket er gavnligt for mental sundhed. Regelm√¶ssig motion fremmer desuden en sund v√¶gt og forbedrer livskvaliteten.  
Feedback: Svaret er nu pr√¶cist og informativt. Der er ikke mere feedback, da det d√¶kker emnet godt.

[Madaan et al. 2023](https://arxiv.org/pdf/2303.17651) har testet metoden p√• outputtet af syv opgaver, for eksempel at optimere kode og omskrive anmeldelser til det modsatte synspunkt. Alle outputs blev forbedret med mellem 5%-40%.`}
   
              ]},
        {
          id: "brug-af-relevant-vidensgenerering",
          title: "üìñ Brug af relevant vidensgenerering",
          content: `En m√¶ngde teknikker bruger vidensgenerering til at forbedre sprogmodellens svar. Det kan se lidt forskelligt ud, som vi vil f√• at se i de n√¶ste metoder, men f√¶lles for dem alle er, at sprogmodellen genererer relevante tekster og informationer, f√∏r den l√∏ser dens opgave. 

At generere relevant viden fungerer meget i samme stil som metoderne, hvor sprogmodellen f√•r tid til at ‚Äút√¶nke‚Äù. Det vil sige, at modellen ved f√∏rst at generere viden, sporer sig selv bedre ind p√•, hvad den skal bruge til at svare p√• sp√∏rgsm√•let, og derfor har en bedre chance for at svare rigtigt og godt. Det kan svare lidt til, hvis man f√∏r man begynder at skrive en stil, s√¶tter sig ned og brainstormer omkring emnet og skriver informationer ned, som man skal huske at inkludere. 
`,
          implementations: [
            {
              id: "generated-knowledge-prompting",
              title: "1. Generated Knowledge Prompting",
              content: `I Generated Knowledge Prompting beder vi f√∏rst sprogmodellen om at generere relevante informationer, f√∏r vi beder den om at udf√∏re en opgave. Det kan for eksempel v√¶re som forneden:

System:	Skriv fem grunde til, at det kan v√¶re nyttigt at l√¶re om prompt engineering.  
Bagefter, skriv et sp√¶ndende, men kort LinkedIn post om fordelene ved at l√¶re prompt engineering, hvor du inkluderer de tidligere grunde. 

Denne metode kan enten udf√∏res i et prompt som foroven, eller i flere prompts, hvor man f√∏rst sp√∏rger sprogmodellen om at generere fakta og bagefter sp√∏rger den om at skrive en tekst ud fra det. Man kan ogs√• bruge metoden til at besvare fakta-baserede sp√∏rgsm√•l. For eksempel kan den svare p√•, hvor hurtig en l√∏ve og tiger kan l√∏be, f√∏r den svarer p√•, hvilken er hurtigst.`
},
          {
            id: "step-back-prompting",
            title: "2. Step-Back Prompting",
            content: `I Step-Back prompting beder vi sprogmodellen om at tage et ‚Äúskridt tilbage‚Äù og lave nogle refleksioner om viden, der kunne v√¶re relevant for sp√∏rgsm√•let. Det kunne man for eksempel g√∏re som forneden:

System:	Du vil lige om lidt blive spurgt om et sp√∏rgsm√•l. N√•r du svarer p√• sp√∏rgsm√•let, skal du g√∏re det i 3 trin:  
1. Bestem hvilke koncepter og viden er relevant for at besvare sp√∏rgsm√•let  
2. Brug koncepterne og viden til at besvare sp√∏rgsm√•let  
3. Besvar sp√∏rgsm√•let

`  
},
        {
          id: "recitation-augmented-language-models",
          title: "3. Recitation-Augmented Language Models",
          content: `Recitation-Augmented Language models er en teknik, hvor modellen henter, eller reciterer, relevante informationer som del af dens svar. Den her metode er forskellig fra de to foroven, fordi den kr√¶ver, at man har givet sin sprogmodel en stor m√¶ngde tr√¶ningsdata. I [Sun et al. 2023](https://arxiv.org/pdf/2210.01296), hvor metoden f√∏rst blev introduceret, havde de for eksempel tr√¶net deres model p√• data fra Wikipedia. Standard online sprogmodeller s√•som ChatGPT kan ikke recitere passager fra deres tr√¶ningsdata. 

Metoden involverer to trin:
1. Sprogmodellen finder dokumenter i dens tr√¶ningsdata, som kan hj√¶lpe den med at besvare sp√∏rgsm√•let. Hvis der er mange, kan en algoritme hj√¶lpe med at v√¶lge de bedste passager  
2. Sprogmodellen citerer en eller flere relevante passager og kommer derefter med dens svar

**Fordel**  
- Recitation-Augmented Language models er is√¶r nyttige i situationer, hvor det er vigtigt at kunne dobbeltchecke, at svaret er rigtigt. Hvis brugeren kan se, hvad modellen har baseret svaret p√•, er det lettere at verificere, om det er et godt svar. 

**Problem**  
- Det er sv√¶rt og tager lang tid at opdatere tr√¶ningss√¶ttet, da modellen s√• skal tr√¶nes forfra. Hvis tr√¶ningss√¶ttet ikke bliver opdateret, kan informationen indenfor nogle omr√•der v√¶re for√¶ldet.`
      }
        ]
        },
        {
          id: "chain-of-thought",
          title: "üîó Chain of Thought",
          content: `Chain of Thought er endnu en metode, hvor man hj√¶lper sprogmodellen til at ‚Äút√¶nke‚Äù. Her sker det ved at man beder modellen om at ‚Äút√¶nke h√∏jt‚Äù, alts√• at vise og forklare dens tankegang. Det er en af de mest popul√¶re metoder, hvis ikke den *mest* popul√¶re, til at forbedre sprogmodellers svar. 

### **Hvorfor er det nyttigt?**

1. *Tankeprocess:* Det hj√¶lper dig med at forst√•, hvordan sprogmodellen n√•r frem til sine konklusioner. Det er en sp√¶ndende mulighed for at l√¶re om dens tankeprocess\!  
2. *Fejlfinding:* Det kan afsl√∏re eventuelle fejl i sprogmodellens r√¶sonnement. Det g√∏r det ogs√• lettere for dig at identificere hvor, den er g√•et galt, og pege den i rette retning  
3. *Bedre svar:* Det giver ofte bedre, mere detaljerede og gennemt√¶nkte svar

### **Simpel implementering**

At implementere Chain of Thought er i teorien s√• simpelt som at skrive en enkelt instruks, hvor man beder modellen om at dele dens "tankeprocess". Det kunne man for eksempel g√∏re som forneden:

System:	Forklar, trin for trin, hvordan man finder kvadratroden af 256 

### **Avanceret eksempel:**

Der findes mange og mere advancerede implementeringer af Chain of Thought end den foroven. Her viser vi en implementering, som kr√¶ver flere trin:
1. Start med at definere problemet klart.  
2. Bed AI'en om at opdele problemet i mindre dele eller trin.  
3. Anmod om en forklaring for hvert trin.  
4. Bed om en endelig konklusion baseret p√• de gennemg√•ende trin.

Eksempel:

System:	Lad os l√∏se f√∏lgende problem trin for trin: En butik s√¶lger T-shirts for 150 kr. stykket. Hvis man k√∏ber 3 eller flere, f√•r man 20% rabat p√• hele k√∏bet. Alice k√∏ber 4 T-shirts. Hvor meget skal hun betale?  
1. Identificer f√∏rst de relevante oplysninger i problemet.  
2. Beregn den oprindelige pris for 4 T-shirts uden rabat.  
3. Afg√∏r om Alice er berettiget til rabatten og forklar hvorfor.  
4. Beregn rabatbel√∏bet.  
5. Tr√¶k rabatten fra den oprindelige pris for at finde den endelige pris.  
6. Giv det endelige svar og opsummer beregningen.  
Venligst vis din tankegang for hvert trin.

Forneden introducerer vi overbygninger til Chain of Thought, som kan g√∏re metoden endnu bedre. 
`,
          implementations: [  
            {
              id: "self-consistency-metode",
              title: "1. Self-consistency metode med Chain of Thought",
              content: `I denne metode beder man ogs√• sprogmodellen om at vise sin tankegang, men man genererer flere svar. Derefter f√•r man modellen til at v√¶lge det bedste svar, fra de svar, den har genereret. Det g√∏r man ofte ved ‚Äúmajority rule‚Äù, hvor den v√¶lger det svar, der er blevet genereret flest gange, men man kan ogs√• specificere en anden standard. For eksempel, hvis svaret er en tekst generering, kan man f√• den til at vurdere det bedste svar ved at sammenligne hvilke temaer og formuleringer, der er gennemg√•ende. 

System:	Du skal finde ud af, hvad 12 ganget med 3 er. Du skal vise din tankegang, mens du laver udregningerne. G√∏r dette 4 gange og v√¶lg derefter det svar, som du f√•r mest ofte.
Assistant: Her er mine udregninger:  
1\. 10x3 \= 30; 2x3 \= 6; 30 \+ 6 \= 36  
2\. (10 \+ 2)x3 \= (10x3) \+ (2x3) \= 30 \+ 6 \= 36  
3\. 10x3 \= 30; 30 x2 \= 60  
4\. 12 er 3x4 s√• 12x3 er 3x(4x3) \= 3x12 \= 36  
1,2, og 4 giver alle 36, s√• 36 er svaret.

Hvis problemerne er meget komplekse og sprogmodellen har brug for meget plads til at vise sin tankegang, kan man i stedet splitte sin prompt op og sp√∏rge sprogmodellen om at komme med svar af flere omgange, f√∏r man beder den om at sammenligne svarene og finde det bedste.   
`},
        {
          id: "complexity-based-prompting",
          title: "2. Complexity-based prompting",
          content: `Denne metode g√•r ud fra, at n√•r vi genererer et svar ved hj√¶lp af Chain of Thought, s√• performer svar med flere ‚Äúreasoning steps‚Äù, det vil sige flere mellemtrin, generelt bedre. Den teori er blevet testet i for eksempel [Fu et al. (2023)](https://openreview.net/pdf?id=yf1icZHC-l9), hvor svar med flere mellemtrin gennemsnitlig var mere n√∏jagtige. Man kan implementere dette p√• to m√•der:

- Man kan bruge complexity som et udv√¶lgelseskriterium i self-consistency metoden  
- Man kan bede sprogmodellen om at generere mange eller en specificeret m√¶ngde mellemtrin`
},
    {
      id: "chain-of-thought-med-og-uden-eksempler",
      title: "3. Chain of Thought med og uden eksempler",
      content: `Eksemplerne vi hidtil har beskrevet er **zero shot** eksempler p√• Chain of Thought, hvilket betyder at vi ikke har givet sprogmodellen nogle eksempler p√• hvilke mellemtrin, vi forventer. N√•r man kombinerer Chain of Thought med **few shot** prompting, det vil sige, man giver den eksempler p√• tankegangen og mellemtrinene, man gerne vil have den til at generere, s√• hedder det **Manual Chain of Thought**. Manual Chain of Thought performer tit bedre end Zero Shot Chain of Thought, men kr√¶ver til geng√¶ld, at man laver eller har eksempler, man kan give sprogmodellen.

Et alternativ til Zero Shot og Manual Chain of Thought er **Auto Chain of Thought**. I Auto Chain of Thought genererer sprogmodellen selv sine egne eksempler, som den kan bruge til at tr√¶ne sig selv. I stedet for b√•de at pr√¶sentere sprogmodellen for et sp√∏rgsm√•l og et svar eksempel, pr√¶senterer man den kun for en m√¶ngde sp√∏rgsm√•l. Ud fra de sp√∏rgsm√•l genererer den selv svar med mellemtrin som en iterativ Zero Shot Chain of Thought. Svarene med mellemtrin, den har genereret, bruger den til sidst som eksempel til at svare bedst muligt p√• det sp√∏rgsm√•l, man egentlig √∏nsker svar p√•. Man kan t√¶nke det som om, at sprogmodellen √∏ver sig, f√∏r den rigtigt svarer. 

### **Trin i Auto Chain of Thought**
- Man giver sprogmodellen en m√¶ngde sp√∏rgsm√•l og beder den svare p√• sp√∏rgsm√•lene ved at vise sin tankegang  
- Sp√∏rgsm√•lene, tankegangen og svarene bliver fordret tilbage til sprogmodellen som eksempler  
- Sprogmodellen svarer p√• et nyt sp√∏rgsm√•l og viser sin tankegang

Auto Chain of Thought minder meget om en anden metode, som hedder **Analogical prompting**. I Analogical prompting beder man ogs√• modellen om at generere eksempler f√∏r, den svarer, men her finder modellen ogs√• p√• sine egne sp√∏rgsm√•l. Man skal derfor hverken have sp√∏rgsm√•l eller svar forberedt i den metode. [Research](https://www.prompthub.us/blog/using-analogical-prompting-to-generate-in-context-examples) peger p√•, at det er ideelt at bede modellen om at generere 3-5 svar-sp√∏rgsm√•l par, f√∏r den svarer.`
}
  ]
      },
        {
          id: "least-to-most-prompting",
          title: "üå±‚û°Ô∏èüå≥ Least-to-Most Prompting",
          content: `Least-to-Most prompting er et alternativ til Chain of Thought, som kr√¶ver en smule mere hj√¶lp fra brugeren, men som til geng√¶ld kan v√¶re bedre til komplekse problemstillinger. Denne metode er is√¶r god til tekstbaserede matematik problemer. 

I Least-to-Most prompting sp√∏rger man f√∏rst sprogmodellen, hvilke underproblemer, den skal l√∏se, for at l√∏se det overordnede problem. Efter sprogmodellen har identificeret underproblemerne, l√∏ser man dem en efter en. Typisk sker dette ved hj√¶lp af en r√¶kke prompts, hvor svarene til hver underproblem bliver en del af det nye prompt, men man kan ogs√• g√∏re det i et samlet prompt. Forneden er et eksempel:

System:	Du f√•r matematik problemer, som du skal l√∏se. Du skal l√∏se dem ved f√∏rst at lave en liste over underproblemer, som skal l√∏ses. Derefter skal du l√∏se hvert problem og til sidst komme med svaret til opgaven. G√• igennem problemet trin for trin.  
User:		En landmand har en mark, der er 120 meter lang og 80 meter bred. Han skal plante tr√¶er langs markens omkreds. Hvert tr√¶ plantes 5 meter fra hinanden. Hvor mange tr√¶er skal han plante?
Assistant:	Underproblemer:  
1. Beregn markens omkreds  
2. Find ud af, hvor mange tr√¶er, der kan plantes langs omkredsen, n√•r de skal plantes 5 meter fra hinanden  
L√∏sning af underproblemer:  
1. Beregn markens omkreds:  
Markens omkreds O kan beregnes ved hj√¶lp af formlen:  
O=2√ó(l√¶ngde+bredde)  
Hvor l√¶ngden er 120 meter og bredden er 80 meter.  
O=2√ó(120m+80m)=2√ó200m=400m  
2. Find ud af, hvor mange tr√¶er der kan plantes langs omkredsen:  
For at finde antallet af tr√¶er N, som skal plantes, bruger vi f√∏lgende formel:  
N= O/(afstand mellem tr√¶er)  
Afstanden mellem tr√¶er er 5 meter, s√• vi kan beregne:  
N= 400 m/ 5m \= 80  
Samlet l√∏sning: Landmanden skal plante 80 tr√¶er langs markens omkreds.`
        }
      ]
    },
    {
      id: "ekspert",
      title: "Ekspert",
      content: `I den her sektion pr√¶senterer vi metoder, hvor vi inkluderer eksterne redskaber som for eksempel en anden (sprog)model til at forbedre vores prompts. Flere af metoderne kr√¶ver kompetencer indenfor kodning. Det er ikke en fuldkommen gennemgang af metoderne, da man kunne skrive en l√¶ngere guide til hver, men metoderne her beskrevet kan forh√•bentlig give inspiration til videre research.`
        ,
      icon: "üèÜ",
      methods: [
        {
          id: "load-data-ved-hjaelp-af-embeddings",
          title: "üìÇ Load data ved hj√¶lp af embeddings",
          content: `Vi har allerede n√¶vnt hvordan sprogmodellers begr√¶nsede ‚Äúcontext window‚Äù betyder at store m√¶ngde tekster ikke kan blive tilf√∏jet som input af en bruger eller i en prompt. Det kan for eksempel v√¶re nyttigt at uploade en kilde med opdateret og trov√¶rdigt information, eller at gemme lange tidligere samtaler i prompten som kontekst for nye samtaler. Se evt. [[Del komplekse opgaver op i mindre dele]] og [[Giv reference tekster]].

For at komme omkring denne begr√¶nsning, kan man i stedet konvertere sin tekst til ‚Äúembeddings‚Äù. Embeddings er en konvertering af tekst til vektorer, som sprogmodeller kan bruge til at sammenligne afstande for at identificere semantiske ligheder mellem ord, s√¶tninger eller tekster. Der er en r√¶kke databaser, man kan bruge til at konvertere tekst til vektorer, for eksempel chromadb. [Her](https://cookbook.openai.com/examples/vector_databases/readme) er en liste, der kan give et overblik over gode databaser. 

Denne metode bliver for eksempel brugt til Retrieval-Augmented Generation (RAG) chatbots, som er meget popul√¶re. En RAG chatbot kombinerer styrken fra offentlige sprogmodeller, oftest OpenAI‚Äôs, med specialiseret viden fra dokumenter loadet med embeddings. Man kunne for eksempel programmere en RAG, som er ekspert indenfor [jura](https://ailex.dk/) eller Danmarks elektriker og vvs-branche.

### **Nogle fordele ved RAGs**

- *Kontekstuelle svar:* RAG-chatbots kan give mere relevante svar, fordi de er tr√¶net indenfor et specifikt omr√•de.   
- *Opdateret information:* RAG-chatbots kan let blive opdateret, s√• de har det nyeste data og informationer. Offentlige sprogmodeller bliver ikke lige s√• tit opdateret.   
- *Korrekt information:* RAG-chatbots kan give mere korrekte oplysninger, da de ofte er tr√¶net p√• data, som er blevet specielt udvalgt, og derfor kan v√¶re mere trov√¶rdig.   
- *Links*: RAG-chatbot kan ofte give links til data, de har brugt til at besvare et sp√∏rgsm√•l. Det g√∏r det lettere at dobbelt-checke vigtig information og bruge svaret til videre research.   
- *Personaliserede:* RAG-chatbots er specialiserede indenfor specifikke omr√•der. Man kan derudover give chatbotten specifikke informationer eller v√¶rkt√∏jer, som kan g√∏re den bedre til at l√∏se en given opgave.   
- *Fejlh√•ndtering:* RAG-chatbotter er bedre til at indr√∏mme, hvis de ikke ved noget, og de ikke kan give et godt svar. Her finder generelle sprogmodeller ofte p√• et svar, n√•r de ikke har nok information. 

Det er ikke s√• besv√¶rligt at programmere sin egen RAG, og man kan finde flere gode tutorials online, for eksempel den [her](https://medium.com/@suraj_bansal/build-your-own-ai-chatbot-a-beginners-guide-to-rag-and-langchain-0189a18ec401). `
        },
        {
          id: "implementer-kode-i-din-prompt",
          title: "üíª Implementer kode i din prompt",
          content: `Sprogmodeller f√•r ofte kritik for at fejle selv simple opgaver. For eksempel har mange forg√¶ves fors√∏gt at f√• ChatGPT til korrekt at t√¶lle m√¶ngden af bogstavet ‚Äúr‚Äù i ordet ‚Äústrawberry‚Äù. Det er fordi, at sprogmodeller fungerer ved, at de g√¶tter det n√¶ste token, alts√• det n√¶ste bogstav eller ord. Det er en *sprog*model, og kan derfor ikke lave udregninger selv. Den kan derfor for eksempel komme til at g√¶tte, at der er 2 r‚Äôer i stedet for 3\. Dog ville en simpel python kode let kunne udregne hvor mange r‚Äôer, der er i ordet ‚Äústrawberry‚Äù:
          
    r_t√¶ller = "strawberry".count("r")

Sprogmodeller kan ikke eksekvere kode. Dog kan man, hvis man programmerer sin egen sprogmodel, give den ekstra funktionalitet i form af kode. Koden bliver ikke eksekveret af sprogmodellen, men for eksempel Python interpreter kan k√∏re koden, hvis man har givet modellen adgang til det. 

System:	Du kan bruge Python kode til at svare p√• et sp√∏rgsm√•l. Python koden er omringet af tre backticks. Brugerne vil gerne vide, hvor mange bogstaver der er i et ord. Her er en kode, du kan bruge:   
    letter\_counter \= word.count(letter)    
Lad ordet v√¶re ‚Äúword‚Äù og bogstavet v√¶re ‚Äúletter‚Äù. Giv svaret i ‚Äúletter\_counter‚Äù. 

I prompten kan du ogs√• kalde eksterne API‚Äôer og bruge det i en kode eksekvering. Der skal du dog passe p√•, at du ikke k√∏rer noget kode, som kan skabe problemer for dig eller din bruger. `
        },
        {
          id: "lav-kald-til-eksterne-systemer",
          title: "üåê Lav kald til eksterne systemer",
          content: `Der findes flere indbyggede funktioner, som man kan kalde i sit prompt. Et eksempel er i OpenAI, hvor man kalder eksterne systemer med [‚Äúfunction calling‚Äù](https://platform.openai.com/docs/guides/function-calling). 

OpenAI identificerer fem kontekster, hvor det kan v√¶re nyttigt at bruge deres function calling:

1. *F√• assistenter til at hente data:* Hvis en bruger sp√∏rger en kundeservice chatbot om for eksempel, hvad deres sidste ordrer var, s√• kan en AI assistent hente data fra et internt system og besvare sp√∏rgsm√•let  
2. *Lad assistenten tage handlinger:* Hvis en AI kan tage handlinger, s√• kan den for eksempel booke et m√∏de for brugeren eller bestille en vare.  
3. *Lad assistenter lave udregninger:* En sprogmodel er ikke s√¶rlig god til at lave udregninger. I stedet kan den forbinde til en matematik funktion, der kan hj√¶lpe.  
4. *Byg gode arbejdsprocesser:* AI‚Äôen kan bruge en dataudtr√¶kningspipeline, der indsamler r√• tekst, konverterer den til strukturerede data og gemmer den i en database.  
5. *Modificer din UI:* Et function call kan opdatere din apps UI baseret p√•, hvad brugeren skriver. Det kunne for eksempel v√¶re at s√¶tte en ny lokation p√• et kort. 

Ligesom i den sidste metode, hvor vi implementerer kode, s√• kan sprogmodellen ikke selv implementere noget af det foroven. Det kr√¶ver at eksterne systemer kan implementere det for modellen. Det er kun modellens job at identificere og bestemme hvilke af funktionerne, der skal implementeres. `
        },
        {
          id: "tree-of-thought",
          title: "üå≥ Tree of Thought",
          content: `Tree of Thoughts er en prompting metode, som bygger ovenp√• [[Chain of Thought]].

I stedet for at bede sprogmodellen om at evaluere tankegangen i et eller flere svar, evaluerer vi her hvert trin i probleml√∏sningen. Hvis modellen har g√•et galt i et trin, s√• kan vi g√• tilbage til et tidligere trin. Det f√∏rer til en matrix baseret tilgang i sammenligning med den line√¶re tilgang i Chain of Thought. Nedenfor er en illustration af [Yao et al. (2023)](https://arxiv.org/abs/2305.10601), som f√∏rst foreslog metoden:

Image: /ToT.png

I illustrationen ser vi:
- Normal input-output prompting, det vil sige standard prompting uden Chain of Thought eller Tree of Thought, genererer et output uden nogle mellemtrin.   
- I Chain of Thought tilf√∏jer vi mellemtrin i form af en synlig tankegang.   
- N√•r vi tilf√∏jer Self Consistency, begynder sprogmodellen ogs√• at overveje alternative m√•der at l√∏se problemet.   
- Tree of Thoughts udforsker flere muligheder for hver mellemtrin, eller ‚Äútanke‚Äù, og vurderer hvor ‚Äúgod‚Äù hver tanke er, f√∏r den forts√¶tter. I diagrammet er ‚Äúgode‚Äù tanker i gr√∏nne nuancer og ‚Äúd√•rlige‚Äù tanker i r√∏de nuancer. Hvad der konstituere en ‚Äúgod‚Äù eller ‚Äúd√•rlig‚Äù tanke skal specificeres for modellen, s√• den ved, hvordan den skal bed√∏mme dens output. 

Tree of Thoughts er inkluderet i ekspert sektionen fordi den normalt bliver implementeret ved hj√¶lp af kode. Koden sender flere prompts til sprogmodellen og beder den stoppe efter hver trin for at evaluere dens output. Hvis man ikke selv vil programmere en iterativ Tree of Thought prompter, kan man bruge et eksisterende bibliotek, for eksempel [her](https://github.com/princeton-nlp/tree-of-thought-llm) eller [her](https://python.langchain.com/api_reference/experimental/tot.html).

En mere simpel version af Tree of Thought kr√¶ver dog ikke programmeringsevner. [Dave Hulbert](https://github.com/dave1010/tree-of-thought-prompting?tab=readme-ov-file) har implementeret Tree of Thought logik ved at give sprogmodellen et eksempel med tre eksperter. Forneden har vi oversat hans originale prompt til dansk:

System:	Der er tre eksperter, som skal besvare et sp√∏rgsm√•l.  
Alle eksperter skriver ned, hvad de t√¶nker i forhold til det f√∏rste skridt og deler det med gruppen.  
Derefter forts√¶tter eksperterne til de n√¶ste skridt, indtil de finder et svar.  
Hvis en af eksperterne indser, at de har taget fejl, g√•r vedkommende.  
Sp√∏rgsm√•let er ‚Ä¶

Tree of Thought kan v√¶re s√¶rlig god til komplekse opgaver, men er un√∏dvendig for simple opgaver.`
        },
        {
          id: "meta-prompting-til-at-lave-nye-prompts",
          title: "üß† Meta Prompting til at lave nye prompts",
          content: `Det kan v√¶re tidskr√¶vende at skrive perfekte prompts. I stedet kan du f√• din sprogmodel til at lave sine egne prompts. En meget let implementering ville v√¶re at beskrive en opgave til sprogmodellen og bede den om at skrive en bedre prompt. Det er dog ikke sikkert, at sprogmodellen er s√¶rlig god til at skrive prompts, og derfor kr√¶ver den nok en del instruktion. 

Der er online prompts generators, som er tr√¶net til at omskrive prompts, s√• man kan f√• mest muligt ud af sprogmodellen. Der er gratise prompt generators, for eksempel [den her](https://beta.pickaxeproject.com/axe?id=Meta_Prompt_God_OCVXI&chat=TMV4Y1GAABPZ2YMDO5MH), og ogs√• nogle, der koster lidt, som [den her](https://metricsmule.com/ai/prompt-generators/). 

Selvf√∏lgelig ville det v√¶re meget sjovere at instruere vores egen prompt generator, hvilket vi kan g√∏re igennem meta prompting. Da dette kr√¶ver mange instruktioner, ofte i et loop, bliver den her metode oftest implementeret igennem programmering. Et eksempel p√• s√•dan kode kan findes [her](https://github.com/meta-prompting/meta-prompting?tab=readme-ov-file). Et andet eksempel er [Anthropics kode](https://colab.research.google.com/drive/1g4xQ63mgTtVuvWzRzfTR8erpWBMovswz?usp=sharing), som ogs√• er hurtig og let at implementere selv.`
        },
        {
          id: "valg-af-gode-eksempler-og-active-prompting",
          title: "‚úÖ Valg af gode eksempler og Active Prompting",
          content: `Hvis man inkluderer eksempler i for eksempel sin Chain of Thought prompt (se: [[Chain of Thought med og uden eksempler]]), er det ikke ligemeget hvilke eksempler, det er. Det er der flere grunde til:

1.  *Upassende eksempler*

Det kan v√¶re, at du vil have modellen til at l√∏se et komplekst problem, men har givet simple eksempler, eller modsat. Det kan ogs√• v√¶re, den har f√•et eksempler fra tekst-genererings opgaver, men skal l√∏se en matematisk opgave. I s√•danne tilf√¶lde kan eksemplerne forvirre modellen og endda forv√¶rre outputtet, fordi den tror, at den skal bruge en upassende fremgangsm√•de til at l√∏se problemet

2.  *Forkerte eksempler*

P√• samme m√•de er det ikke ideelt, hvis modellen f√•r eksempler, hvor der er fejl. Det kan v√¶re, at tankegangen eller svaret er forkert, og det kan ogs√• lede modellen p√• afveje. Man kan s√∏rge for, at eksemplerne er korrekte ved at have mennesker til at generere eller annotere dem, som i Manual Chain of Thought. Det kan dog v√¶re meget tidskr√¶vende og dyrt at lave eller checke mange eksempler. 

### **Active Prompting**

Active Prompting er blevet foresl√•et som en l√∏sning til iterativt at mindske forkerte eksempler. Det g√∏r den ved f√∏lgende metode:

**1\. Uncertainty Estimation:**  
- Sprogmodellen bliver pr√¶senteret for en m√¶ngde sp√∏rgsm√•l, som den skal tr√¶ne p√•.   
- Den besvarer alle sp√∏rgsm√•lene med Chain of Thought en hvis m√¶ngde gange.   
- Sp√∏rgsm√•lene bliver scoret p√•, hvor usikker modellen er p√• svaret. Det kan for eksempel v√¶re, at svar hvor modellen har f√•et det samme svar 4 ud af 5 gange er 20% usikker. Andre metoder kan ogs√• bruges, dog skal man huske at det ikke er s√¶rlig v√¶rdifuldt at sp√∏rge modellen om, hvor sikker den er, da sprogmodeller generelt fremst√•r meget sikre.   
          
**2\. Selection:**  
- Sp√∏rgsm√•lene, hvor modellen er mest usikker, bliver udvalgt


**3\. Annotation:**  
- De udvalgte sp√∏rgsm√•l bliver annoteret, det vil sige rettet, manuelt

**4\. Final Inference:**  
- De rettede usikre svar samt de mere sikre svar kan bruges som tr√¶nings eksempler i en Chain of Thought prompt

P√• den m√•de kan modellen generere langt de fleste af dens egne eksempler og kun de eksempler, hvor den virker usikker og laver fejl, bliver rettet til manuelt af et eller flere mennesker. Det sparer tid og dermed ogs√• penge. Til geng√¶ld koster det regnekraft og mange tokens og dermed ogs√• penge at finde frem til sp√∏rgsm√•lene, der skal annoteres. `
        },
        {
          id: "lav-systematiske-aendringer-og-test-det",
          title: "üß™ Lav systematiske √¶ndringer og test det",
          content: `Hvordan ved man, om ens prompt √¶ndringer har gjort modellens svar bedre eller v√¶rre? Hvad hvis man har tilf√∏jet en prompt, som forh√∏jer den n√∏dvendige regnekraft, eller f√•r modellen til at performe langsommere, men dette f√∏rer ikke til en stor forbedring i svar? Man kan selvf√∏lgelig kigge p√• svarene individuelt og vurdere deres kvalitet, men hvis man har en model, som skal tilg√•s af mange brugere med en bred vifte af sp√∏rgsm√•l, s√• kan det give mere mening at lave systematiske tests. 

### **Hvordan tester jeg bedst min sprogmodel?**

- *Videnskabelig tilgang:* Det er vigtigt, n√•r man tester, at man kun laver f√• √¶ndringer af gangen, s√• man kan g√• tilbage og finde ud af, hvilke prompts der har v√¶ret nyttige og ikke nyttige.   
- *Kvalitetsvurdering:* Man kan teste ens model ved at sp√∏rge den en r√¶kke sp√∏rgsm√•l med klare svar eller ved at bruge en anden model til at vurdere kvaliteten.   
- *Svarudvalg:* Sp√∏rgsm√•lene skal v√¶re brede og repr√¶sentative for de sp√∏rgsm√•l, brugerne kan finde p√• at stille, og der skal v√¶re mange af dem, s√• resultaterne bliver statistisk signifikante.

Nedenunder er *et* eksempel p√•, hvordan man kan bruge en prompt til at evaluere et svar:

System: Du vil blive pr√¶senteret for et sp√∏rgsm√•l, et ideelt svar, og et svar, som du skal vurdere (‚Äúvurderings svar‚Äù).  
Trin 1: Skriv tre punkter for, hvad du vurderer at v√¶re de tre vigtigste informationer i det ideelle svar baseret p√• sp√∏rgsm√•let.  
Trin 2: For hver punkt, vurder hvorvidt vurderings svaret kommer ind p√• punktet. Skriv ‚Äúja‚Äù udfra punktet, hvis punktet bliver d√¶kket korrekt.  
Trin 3: T√¶l hvor mange ‚Äúja‚Äôer‚Äù, der er, og giv det som en endelig score. Skriv: {score: \<score\>}  
User: Sp√∏rgsm√•l: Hvem er i den danske kongefamilie, og hvem er regenten i 2024?  
Ideelt svar: Det nuv√¶rende danske kongehus ledes af kong Frederik 10\. og dronning Mary, som er hans gemalinde. De har fire b√∏rn: kronprins Christian, prinsesse Isabella samt tvillingerne prins Vincent og prinsesse Josephine. Dronning Margrethe II abdicerede den 14\. januar 2024, men forbliver en del af kongehuset. Desuden inkluderer familien kongens yngre bror, prins Joachim, og hans fire b√∏rn: grev Nikolai, grev Felix, grev Henrik og komtesse Athena, samt dronning Margrethe II.s s√∏ster, prinsesse Benedikte.  
Vurderings svar: Den danske kongefamilie best√•r af dronning Margrethe II, kronprins Frederik, kronprinsesse Mary, deres b√∏rn prins Christian, prinsesse Isabella, prins Vincent og prinsesse Josephine, samt andre medlemmer af familien. I 2024 er dronning Margrethe II regent. Hun har v√¶ret dronning siden 1972 og er den f√∏rste kvindelige monark i Danmark i over 500 √•r.  
Assistant: Her er min vurderinger:  
1. Kong Frederik 10\. og dronning Mary leder kongehuset og har fire b√∏rn: kronprins Christian, prinsesse Isabella samt tvillingerne prins Vincent og prinsesse Josephine.  
Vurdering: Vurderings svaret n√¶vner ikke kong Frederik 10\. som regent eller forbindelsen til dronning Mary.  
2. Dronning Margrethe II abdicerede den 14\. januar 2024, men forbliver en del af kongehuset.  
Vurdering: Vurderings svaret n√¶vner ikke abdikationen af dronning Margrethe II.  
3. Kongehuset inkluderer ogs√• prins Joachim og hans fire b√∏rn samt prinsesse Benedikte.  
Vurdering: Vurderings svaret n√¶vner ikke prins Joachim eller prinsesse Benedikte.  
{score: 0}`
        }
      ]
    }
  ]
};

const PromptGuide: React.FC = () => {
  return null; // This component doesn't render anything, it's just for exporting the data
};

export default PromptGuide;